{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "839bb893-da21-43d1-b89a-5b727998a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from QualtricsAPI.Setup import Credentials\n",
    "from QualtricsAPI.Survey import Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e482c5-5236-4d56-9b95-103b6b2a1447",
   "metadata": {},
   "source": [
    "# Pilot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68f129ec-7d7e-434d-86e8-9171e9f0a495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>field</th>\n",
       "      <th>rater</th>\n",
       "      <th>binary</th>\n",
       "      <th>abstract</th>\n",
       "      <th>ordinal</th>\n",
       "      <th>rater_disc</th>\n",
       "      <th>pubyear</th>\n",
       "      <th>doi</th>\n",
       "      <th>doctype</th>\n",
       "      <th>group</th>\n",
       "      <th>chauvinism</th>\n",
       "      <th>capture</th>\n",
       "      <th>citation</th>\n",
       "      <th>socialmedia</th>\n",
       "      <th>mention</th>\n",
       "      <th>outlier</th>\n",
       "      <th>usage</th>\n",
       "      <th>present</th>\n",
       "      <th>intolerance</th>\n",
       "      <th>ethics</th>\n",
       "      <th>empirical</th>\n",
       "      <th>environment</th>\n",
       "      <th>education</th>\n",
       "      <th>wellbeing</th>\n",
       "      <th>deliverable</th>\n",
       "      <th>abstract_text</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract_length</th>\n",
       "      <th>abstract_wordcount</th>\n",
       "      <th>field_group</th>\n",
       "      <th>sex</th>\n",
       "      <th>weird</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>HIST</td>\n",
       "      <td>521.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>QID2_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LING</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>10.1080/09612025.2015.1028209</td>\n",
       "      <td>Article</td>\n",
       "      <td>group1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>This article examines the content of Women's C...</td>\n",
       "      <td>'Our own paper': evaluating the impact of Wome...</td>\n",
       "      <td>757</td>\n",
       "      <td>115</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>M</td>\n",
       "      <td>WEIRD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HIST</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>QID2_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>10.1080/09612025.2015.1028209</td>\n",
       "      <td>Article</td>\n",
       "      <td>group1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>This article examines the content of Women's C...</td>\n",
       "      <td>'Our own paper': evaluating the impact of Wome...</td>\n",
       "      <td>757</td>\n",
       "      <td>115</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>M</td>\n",
       "      <td>not WEIRD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  block field  rater  binary abstract  ordinal rater_disc  pubyear  \\\n",
       "0     2  HIST  521.0     0.0   QID2_1      0.0       LING   2015.0   \n",
       "1     2  HIST  142.0     0.0   QID2_1      0.0       PHIL   2015.0   \n",
       "\n",
       "                             doi  doctype   group  chauvinism  capture  \\\n",
       "0  10.1080/09612025.2015.1028209  Article  group1         0.0     30.0   \n",
       "1  10.1080/09612025.2015.1028209  Article  group1         0.0     30.0   \n",
       "\n",
       "   citation  socialmedia  mention  outlier   usage  present  intolerance  \\\n",
       "0       3.0          7.0      0.0      0.0  1021.0      0.0          1.0   \n",
       "1       3.0          7.0      0.0      0.0  1021.0      0.0          1.0   \n",
       "\n",
       "   ethics  empirical  environment  education  wellbeing  deliverable  \\\n",
       "0     0.0        0.0          0.0        0.0        0.0          0.0   \n",
       "1     0.0        0.0          0.0        0.0        0.0          0.0   \n",
       "\n",
       "                                       abstract_text  \\\n",
       "0  This article examines the content of Women's C...   \n",
       "1  This article examines the content of Women's C...   \n",
       "\n",
       "                                               title  abstract_length  \\\n",
       "0  'Our own paper': evaluating the impact of Wome...              757   \n",
       "1  'Our own paper': evaluating the impact of Wome...              757   \n",
       "\n",
       "   abstract_wordcount field_group sex      weird  \n",
       "0                 115  Humanities   M      WEIRD  \n",
       "1                 115  Humanities   M  not WEIRD  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pilot data\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\conix\\Dropbox\\aWriting\\humanities impact\\data\\IIH_all_data.csv\",index_col=\"Unnamed: 0\")\n",
    "df[\"Field_group\"] = \"Humanities\"\n",
    "\n",
    "# there are some wierd NaNs -- check where they come from!!\n",
    "df = df.loc[~df.binary.isna()]\n",
    "\n",
    "# make column names lower case\n",
    "\n",
    "df.columns = [i.lower() for i in df.columns]\n",
    "df = df.rename(columns = {'b3_l':'deliverable'})\n",
    "\n",
    "# add field group columns\n",
    "\n",
    "df['field_group'] = 'Humanities'\n",
    "\n",
    "# add gender\n",
    "\n",
    "pilot_gender = {111:'F',121:'M',132:'M',142:'M',\n",
    "                211:'M',222:'M',232:'F',\n",
    "                311:'M',321:'F',332:'F',342:'F',\n",
    "                411:'F',421:'F',432:'F',\n",
    "                511:'F',521:'M', 532:'F',542:'F'}\n",
    "\n",
    "pilot_weird = {111:'WEIRD',121:'WEIRD',132:'WEIRD',142:'not WEIRD',\n",
    "                211:'WEIRD',222:'not WEIRD',232:'WEIRD',\n",
    "                311:'WEIRD',321:'not WEIRD',332:'WEIRD',342:'WEIRD',\n",
    "                411:'not WEIRD',421:'WEIRD',432:'not WEIRD',\n",
    "                511:'WEIRD',521:'WEIRD', 532:'WEIRD',542:'WEIRD'}\n",
    "df['sex'] = df['rater'].replace(pilot_gender)\n",
    "df['weird'] = df['rater'].replace(pilot_weird)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08bc4f3-f2fa-4a35-803e-785bdac32f5d",
   "metadata": {},
   "source": [
    "# Document data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9489b7a-a6bf-444f-b188-7812dfec31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the abstracts\n",
    "\n",
    "documents = pd.read_csv(r\"C:\\Users\\conix\\Dropbox\\aWriting\\humanities impact\\follow up study\\IIH_followupdata_version3.csv\", sep = \";\").reset_index().rename(columns={\"index\": \"ORIGINAL_INDEX\"})\n",
    "# keep relevant columns and shuffle to avoid order effects\n",
    "documents = documents[[\"ORIGINAL_INDEX\",\"DOI\",\"TITLE\",\"ABSTRACT\",\"PUBYEAR\", \"DOCTYPE\"]]\n",
    "documents.columns = [i.lower() for i in documents.columns]\n",
    "documents = documents.rename(columns = {'abstract':'abstract_text'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c456ff-1416-4ec0-bae7-a4013e8c5585",
   "metadata": {},
   "source": [
    "# Rater data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8f41d50-3c54-43f2-8edc-64d6cefaba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\conix\\Dropbox\\aWriting\\humanities impact\\data\\rater_data.txt\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    rater_data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba06b1bc-aba2-4cad-978f-6196c5aa4abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['block', 'field', 'rater', 'binary', 'abstract', 'ordinal',\n",
       "       'rater_disc', 'pubyear', 'doi', 'doctype', 'group', 'chauvinism',\n",
       "       'capture', 'citation', 'socialmedia', 'mention', 'outlier', 'usage',\n",
       "       'present', 'intolerance', 'ethics', 'empirical', 'environment',\n",
       "       'education', 'wellbeing', 'deliverable', 'abstract_text', 'title',\n",
       "       'abstract_length', 'abstract_wordcount', 'field_group', 'sex', 'weird'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4cde6-049e-40d9-9d97-fad4cb74217d",
   "metadata": {},
   "source": [
    "# Coding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c90da02a-407a-414e-9c42-66c0a3ff1bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "coded_data = pd.read_csv(r\"C:\\Users\\conix\\Dropbox\\aWriting\\humanities impact\\follow up study\\abstract_coding\\IIH_codingStudy2_DisagreementsExcel_corrected.csv\",sep = \";\")\n",
    "\n",
    "# check if there is no disagreement left\n",
    "code_cols = ['A1 time', 'A2 -ism','A3 ethics', 'A4 emp', 'A5 world', 'A6 non-lit', 'B1 edu', 'B2 human', 'B3 deliv']\n",
    "for i in code_cols:\n",
    "    assert (coded_data[i+'_LIN'] == coded_data[i+'_OLI']).sum() == len(coded_data), f\"col {i} has disagreements still\"\n",
    "\n",
    "coded_data = coded_data[['DOI', 'A1 time_LIN', 'A2 -ism_LIN',\n",
    "       'A3 ethics_LIN', 'A4 emp_LIN', 'A5 world_LIN', 'A6 non-lit_LIN',\n",
    "       'B1 edu_LIN', 'B2 human_LIN', 'B3 deliv_LIN']]\n",
    "\n",
    "coded_data.columns = ['doi','present', 'intolerance', 'ethics',\n",
    "       'empirical', 'environment', 'fiction', 'education', 'wellbeing', 'deliverable']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61bcb71-ad2a-4513-be7f-414406604900",
   "metadata": {},
   "source": [
    "# Survey data\n",
    "\n",
    "## Load the data and remove what we don\"t want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdb90f4a-1576-4ea4-80e6-469c5a812173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main study data from qualtrics\n",
    "\n",
    "# credentials to get data via the qualtrics API\n",
    "\n",
    "id_s1 = \"SV_6g14RQpKZGSbx3g\"\n",
    "id_s2 = \"SV_8pGlqv9GqN2OrVI\"\n",
    "id_s3 = \"SV_bQ75Bb7jwCEnHBI\"\n",
    "\n",
    "qtoken =\"4TJ1WJofe3yHbR8duXWSNCxitHQ6d2QjyKwoZ4oz\"\n",
    "            \n",
    "qdc = \"fra1\"\n",
    "\n",
    "# import data through API\n",
    "\n",
    "Credentials().qualtrics_api_credentials(token=qtoken,data_center=qdc)\n",
    "\n",
    "df1 = Responses().get_survey_responses(survey=id_s1)\n",
    "df2 = Responses().get_survey_responses(survey=id_s2)\n",
    "df3 = Responses().get_survey_responses(survey=id_s3)\n",
    "\n",
    "surveys = [df1,df2,df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80d02a17-7513-491d-aab7-450106a6e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols = ([ \"RecordedDate\",\"ResponseId\",\"RecipientLastName\",\"RecipientFirstName\",\"RecipientEmail\",\"ExternalReference\",\n",
    "             \"LocationLatitude\",\"LocationLongitude\",\"DistributionChannel\",\"UserLanguage\", \"Status\",\"IPAddress\", \"Finished\",\"Progress\"])\n",
    "\n",
    "# strore information like when and how long raters worked\n",
    "survey_info = {\"durations\" : [], \"dates\" : [], \"block_times\":[], \"titles\":[]}\n",
    "\n",
    "def clean_surveys(survey):\n",
    "\n",
    "    # store titles for the abstracts\n",
    "    pattern = r\"as well. - (.*?)\\n\\n\\n\\n\"\n",
    "    survey_info[\"titles\"].append([survey[col].str.extract(pattern).iloc[0, 0] for col in survey.columns if ((\"TEXT\" in col) and (\"QID\" in col))])\n",
    "\n",
    "    # only finished surveys\n",
    "    survey = survey.loc[survey.Progress == \"100\"]\n",
    "    \n",
    "    # drop unneeded columns across surveys\n",
    "    survey = survey.drop(columns = dropcols)\n",
    "\n",
    "    # remove the timer columns except for total block time\n",
    "    timer_cols = [i for i in survey.columns if ((\"First\" in i) or (\"Last\" in i) or (\"Count\" in i))]\n",
    "    survey = survey.drop(columns = timer_cols)\n",
    "\n",
    "    # remove test surveys from research team\n",
    "    researchers = [\"stijn\",\"lin\",\"leander\",\"olivier\",\"pei-shan\"]\n",
    "    pattern = \"|\".join(researchers)\n",
    "    survey = survey[~survey[\"QID0\"].str.replace(\"[^a-zA-Z]\", \"\", regex=True).str.contains(pattern, case=False, na=False)]\n",
    "    \n",
    "    # store and remove duration\n",
    "    survey_info[\"durations\"].append(survey[[\"QID0\",\"Duration (in seconds)\"]])\n",
    "    survey = survey.drop(columns = [\"Duration (in seconds)\"])\n",
    "\n",
    "    # store and remove dates\n",
    "    survey_info[\"dates\"].append(survey[[\"QID0\",\"StartDate\",\"EndDate\"]])\n",
    "    survey = survey.drop(columns = [\"StartDate\",\"EndDate\"])\n",
    "\n",
    "    # store and remove block times\n",
    "    block_times = [i for i in survey.columns if \"QT\" in i] + [\"QID0\"]\n",
    "    survey_info[\"block_times\"].append(survey[block_times])\n",
    "    survey = survey[[i for i in survey.columns if \"QT\" not in i]]\n",
    "\n",
    "    # rename QID0 column to ID\n",
    "    survey = survey.rename(columns = {\"QID0\":\"rater\"})\n",
    "\n",
    "    \n",
    "\n",
    "    return survey\n",
    "    \n",
    "df1 = clean_surveys(df1)\n",
    "df2 = clean_surveys(df2)\n",
    "df3 = clean_surveys(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f42280d4-8f45-43c5-9ef0-394a2df8f646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid value found in set 0 at Row: 17, Column: 'QID5_1_TEXT' -> Value: 2\n"
     ]
    }
   ],
   "source": [
    "# There was one rater thrown out because of too many inconsistencies in the first 13 sets, so we remove them\n",
    "\n",
    "df1 = df1.loc[df1.rater != \"211\"]\n",
    "\n",
    "# now check if all surveys have the same number of raters\n",
    "\n",
    "assert len(df1) == len(df2) == len(df3), \"not all surveys have the same number of raters\"\n",
    "\n",
    "# check if all binary data is indeed binary\n",
    "\n",
    "for set,i in enumerate([df1, df2, df3]):\n",
    "    binary_cols = [col for col in i.columns if 'TEXT' in col]\n",
    "    binary_df = i[binary_cols].copy()\n",
    "    invalid_values_mask = binary_df.map(lambda x: x not in ['0', '1'])\n",
    "    invalid_locations = np.where(invalid_values_mask)\n",
    "    positions = list(zip(invalid_locations[0], invalid_locations[1]))\n",
    "    for pos in positions:\n",
    "        row, col = pos\n",
    "        print(f\"Invalid value found in set {set} at Row: {row}, Column: '{binary_df.columns[col]}' -> Value: {binary_df.iloc[row, col]}\")\n",
    "\n",
    "# fix the value that is problematic\n",
    "# we assume that the 2 is supposed to be a 1\n",
    "\n",
    "df1.loc[df1.index[17],'QID5_1_TEXT'] = '1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee63c550-8d9c-4cac-9b8a-75ff94add7cd",
   "metadata": {},
   "source": [
    "## Turn into DF with ratings as rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bd7e630-bf16-40c4-888b-487742faa2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df with as the rows ratings, an as the columns the field, rater, block, rank score and binary score\n",
    "\n",
    "def transform_survey_data(df, set):\n",
    "    df_final = pd.DataFrame(columns=[\"rater\", \"block\", \"field\", \"ordinal\", \"binary\"])\n",
    "    \n",
    "    # Iterate through each QID set\n",
    "    for qid in range(1, 11):  # each set has 10 blocks, we remove the burnin\n",
    "        for position in range(1, 6):  # five papers per block\n",
    "            # Extract relevant columns for the current position and task\n",
    "            rank_col = f\"QID{qid}_{position}\"\n",
    "            binary_col = f\"{rank_col}_TEXT\"\n",
    "            temp_df = df[[\"rater\", rank_col, binary_col]].copy()\n",
    "            temp_df.rename(columns={rank_col: \"ordinal\", binary_col: \"binary\"}, inplace=True)\n",
    "            temp_df[\"block\"] = f\"QID{qid}_{set}\"\n",
    "            temp_df[\"field\"] = position\n",
    "            # Append to the final DataFrame\n",
    "            df_final = pd.concat([df_final, temp_df], ignore_index=True)\n",
    "\n",
    "            # add a column to indicate that these data are not pilot data\n",
    "            df_final[\"group\"] = \"main\"\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "df1 = transform_survey_data(df1,1)\n",
    "df2 = transform_survey_data(df2,2)\n",
    "df3 = transform_survey_data(df3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "125de329-4864-43fc-84e4-e1e459027407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the titles of the abstracts to each row\n",
    "\n",
    "n_raters =  len(df1.rater.unique())\n",
    "\n",
    "df1[\"title\"] = np.repeat(np.array(survey_info[\"titles\"])[0], # get the stored titles\n",
    "                         n_raters) # tile them n_raters times\n",
    "df2[\"title\"] = np.repeat( np.array(survey_info[\"titles\"])[1], # get the stored titles\n",
    "                         n_raters) # tile them n_raters times\n",
    "df3[\"title\"] = np.repeat( np.array(survey_info[\"titles\"])[2], # get the stored titles\n",
    "                         n_raters) # tile them n_raters times\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518aa17c-1bbd-4a6f-8e30-07d721967c20",
   "metadata": {},
   "source": [
    "# Combine with other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43ff15ff-150e-47a9-b662-b7b612a14e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rater</th>\n",
       "      <th>block</th>\n",
       "      <th>field</th>\n",
       "      <th>ordinal</th>\n",
       "      <th>binary</th>\n",
       "      <th>group</th>\n",
       "      <th>title</th>\n",
       "      <th>rater_disc</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Sex</th>\n",
       "      <th>WEIRD</th>\n",
       "      <th>Field_group</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151_main</td>\n",
       "      <td>QID1_1_main</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>main</td>\n",
       "      <td>Does China Matter? Taiwan's Successful Bid to ...</td>\n",
       "      <td>History</td>\n",
       "      <td>Argentinian</td>\n",
       "      <td>M</td>\n",
       "      <td>not WEIRD</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>QID1_1_main_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111_main</td>\n",
       "      <td>QID1_1_main</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>main</td>\n",
       "      <td>Does China Matter? Taiwan's Successful Bid to ...</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>Serbian</td>\n",
       "      <td>M</td>\n",
       "      <td>not WEIRD</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>QID1_1_main_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121_main</td>\n",
       "      <td>QID1_1_main</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>main</td>\n",
       "      <td>Does China Matter? Taiwan's Successful Bid to ...</td>\n",
       "      <td>Linguistics</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>M</td>\n",
       "      <td>not WEIRD</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>QID1_1_main_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rater        block  field  ordinal  binary group  \\\n",
       "0  151_main  QID1_1_main      1        3       0  main   \n",
       "1  111_main  QID1_1_main      1        4       1  main   \n",
       "2  121_main  QID1_1_main      1        1       1  main   \n",
       "\n",
       "                                               title   rater_disc  \\\n",
       "0  Does China Matter? Taiwan's Successful Bid to ...      History   \n",
       "1  Does China Matter? Taiwan's Successful Bid to ...   Philosophy   \n",
       "2  Does China Matter? Taiwan's Successful Bid to ...  Linguistics   \n",
       "\n",
       "   Nationality Sex      WEIRD Field_group       abstract  \n",
       "0  Argentinian   M  not WEIRD  Humanities  QID1_1_main_1  \n",
       "1      Serbian   M  not WEIRD  Humanities  QID1_1_main_1  \n",
       "2      Turkish   M  not WEIRD  Humanities  QID1_1_main_1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, combine all three sets\n",
    "\n",
    "main_study = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# add rater data\n",
    "\n",
    "def map_values(row):\n",
    "    # Extract ID from the row\n",
    "    id_value = row[\"rater\"]\n",
    "    # Look up the inner dictionary using this ID\n",
    "    inner_dict = rater_data.get(id_value, {})\n",
    "    # For each key in the inner dictionary, set the row\"s corresponding column\n",
    "    for key, value in inner_dict.items():\n",
    "        row[key] = value\n",
    "    return row\n",
    "\n",
    "main_study = main_study.apply(map_values, axis=1)\n",
    "\n",
    "# add main to rater column and block column to make sure we don\"t confuse them with data from other studies\n",
    "\n",
    "main_study[\"block\"] = [f\"{i}_main\" for i in main_study.block.values] \n",
    "main_study[\"rater\"] = [f\"{i}_main\" for i in main_study.rater.values] \n",
    "main_study['abstract'] = main_study['field'].replace({'History':'1', 'Philosophy':'2','Religion':'3','Linguistics':'4','Literature':'5'})\n",
    "main_study['abstract'] = main_study['block'] + '_' + main_study['abstract'].astype('string')\n",
    "\n",
    "# make ordinal and binary integer\n",
    "\n",
    "for i in ['binary','ordinal']:\n",
    "    main_study[i] = main_study[i].astype('int32')\n",
    "\n",
    "main_study.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d48153ec-4049-4f28-9337-fa2c88a90835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add documents\n",
    "\n",
    "documents.head(2)\n",
    "\n",
    "# one problem in the merging: one of the titles had a character that had been changed\n",
    "# was in the title: \"God as a true Elohim and Savior of the Poor - Psalm 82 in the Corpus of the Psalms of Asaph\"\n",
    "# replace with the string from the survey\n",
    "\n",
    "documents.loc[documents.title.str.contains(\"Psalm 82\"), \"title\"] = \"God as a true Elohim and Savior of the Poor - Psalm 82 in the Corpus of the Psalms of Asaph\"\n",
    "\n",
    "\n",
    "main_study = documents.merge(main_study, on = \"title\", how = \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d67cdb6-85ab-4933-a413-d8382576c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raters were kicked if they had too many inconsistencies. If they had 1, we allowed them to fix it. \n",
    "\n",
    "data = {}\n",
    "\n",
    "# 7 mistakes in total, 1 in each of the following sets\n",
    "fixes = [\"111\",\"111_set3\",\"121\",\"131\",\"151\",\"212\",\"226_set3\"]\n",
    "\n",
    "for i in fixes:\n",
    "    fixed_data = pd.read_csv(r\"C:\\Users\\conix\\Dropbox\\aWriting\\humanities impact\\follow up study\\raters_fix\\\\\" + i + \"_corrected.csv\", \n",
    "                             dtype = {\"ranks\":'int32','binary':'int32'},\n",
    "                             sep = \";\")\n",
    "    fixed_data.columns = [\"index_col\",\"title\",\"abstract_text\",\"set\",\"ordinal\",\"binary\"]\n",
    "    # for i in ['binary','ordinal']:\n",
    "    #     fixed_data[i] = fixed_data[i].astype('int32')\n",
    "    if \"_\" in i:\n",
    "        rater = i.split(\"_\")[0]\n",
    "        block = i.split(\"set\")[1]\n",
    "    else:\n",
    "        rater = i\n",
    "        block = \"1\"\n",
    "        fixed_data = fixed_data.loc[~fixed_data.set.isin(['set_a','set_b','set_c'])]\n",
    "    \n",
    "    \n",
    "    fixed_data = fixed_data[[\"title\",\"ordinal\",\"binary\"]]\n",
    "    \n",
    "    condition = ((main_study.rater == rater + \"_main\") & (main_study.block.str.contains(\"_\" + block +\"_main\")))\n",
    "    main_study_filtered = main_study.copy().loc[condition]\n",
    "\n",
    "    # combine the fixed and original values in one df for comparison\n",
    "    merged_df = pd.merge(main_study_filtered, fixed_data, on=\"title\", how=\"left\", suffixes=(\"_old\", \"\"))\n",
    "\n",
    "    # replace the originally recorded value by the fixed value\n",
    "    for col in [\"binary\", \"ordinal\"]:\n",
    "        main_study.loc[condition, col] = list(merged_df[col].values)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9c90803-7f30-4113-8882-4cbb29ac26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse ordinal data (to make more valuable a higher score, and less valuable a lower score)\n",
    "\n",
    "main_study['ordinal'] = main_study['ordinal'].astype('int32')\n",
    "main_study['ordinal'] = main_study['ordinal'].replace({1:5,2:4,3:3,4:2,5:1})\n",
    "\n",
    "# make it start at 0 rather than 1\n",
    "main_study['ordinal'] = main_study['ordinal'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c9a41f5-d7db-4087-aef2-40c6a625f311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract_text</th>\n",
       "      <th>pubyear</th>\n",
       "      <th>doctype</th>\n",
       "      <th>rater</th>\n",
       "      <th>block</th>\n",
       "      <th>field</th>\n",
       "      <th>ordinal</th>\n",
       "      <th>binary</th>\n",
       "      <th>group</th>\n",
       "      <th>rater_disc</th>\n",
       "      <th>nationality</th>\n",
       "      <th>sex</th>\n",
       "      <th>weird</th>\n",
       "      <th>field_group</th>\n",
       "      <th>abstract</th>\n",
       "      <th>chauvinism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1080/09523367.2015.1022721</td>\n",
       "      <td>Does China Matter? Taiwan's Successful Bid to ...</td>\n",
       "      <td>This study seeks to identify and explain the k...</td>\n",
       "      <td>2015</td>\n",
       "      <td>Article</td>\n",
       "      <td>151_main</td>\n",
       "      <td>QID1_1_main</td>\n",
       "      <td>History</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>main</td>\n",
       "      <td>History</td>\n",
       "      <td>Argentinian</td>\n",
       "      <td>M</td>\n",
       "      <td>not WEIRD</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>QID1_1_main_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1080/09523367.2015.1022721</td>\n",
       "      <td>Does China Matter? Taiwan's Successful Bid to ...</td>\n",
       "      <td>This study seeks to identify and explain the k...</td>\n",
       "      <td>2015</td>\n",
       "      <td>Article</td>\n",
       "      <td>111_main</td>\n",
       "      <td>QID1_1_main</td>\n",
       "      <td>History</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>main</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>Serbian</td>\n",
       "      <td>M</td>\n",
       "      <td>not WEIRD</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>QID1_1_main_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10.1080/09523367.2015.1022721</td>\n",
       "      <td>Does China Matter? Taiwan's Successful Bid to ...</td>\n",
       "      <td>This study seeks to identify and explain the k...</td>\n",
       "      <td>2015</td>\n",
       "      <td>Article</td>\n",
       "      <td>121_main</td>\n",
       "      <td>QID1_1_main</td>\n",
       "      <td>History</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>main</td>\n",
       "      <td>Linguistics</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>M</td>\n",
       "      <td>not WEIRD</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>QID1_1_main_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index                            doi  \\\n",
       "0               0  10.1080/09523367.2015.1022721   \n",
       "1               0  10.1080/09523367.2015.1022721   \n",
       "2               0  10.1080/09523367.2015.1022721   \n",
       "\n",
       "                                               title  \\\n",
       "0  Does China Matter? Taiwan's Successful Bid to ...   \n",
       "1  Does China Matter? Taiwan's Successful Bid to ...   \n",
       "2  Does China Matter? Taiwan's Successful Bid to ...   \n",
       "\n",
       "                                       abstract_text  pubyear  doctype  \\\n",
       "0  This study seeks to identify and explain the k...     2015  Article   \n",
       "1  This study seeks to identify and explain the k...     2015  Article   \n",
       "2  This study seeks to identify and explain the k...     2015  Article   \n",
       "\n",
       "      rater        block    field  ordinal  binary group   rater_disc  \\\n",
       "0  151_main  QID1_1_main  History        2       0  main      History   \n",
       "1  111_main  QID1_1_main  History        1       1  main   Philosophy   \n",
       "2  121_main  QID1_1_main  History        4       1  main  Linguistics   \n",
       "\n",
       "   nationality sex      weird field_group       abstract  chauvinism  \n",
       "0  Argentinian   M  not WEIRD  Humanities  QID1_1_main_1           1  \n",
       "1      Serbian   M  not WEIRD  Humanities  QID1_1_main_1           0  \n",
       "2      Turkish   M  not WEIRD  Humanities  QID1_1_main_1           0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add field strings\n",
    "\n",
    "field_codes = {1:\"History\",2: \"Philosophy\",3:\"Religion\",4:\"Linguistics\",5:\"Literature\"}\n",
    "main_study[\"field\"] = main_study[\"field\"].replace(field_codes)\n",
    "\n",
    "# add chauvinism\n",
    "\n",
    "main_study[\"chauvinism\"] = main_study.apply(lambda row: 1 if row[\"field\"] == row[\"rater_disc\"] else 0, axis=1)\n",
    "\n",
    "# make column names lower case\n",
    "\n",
    "main_study.columns = [i.lower() for i in main_study.columns]\n",
    "\n",
    "\n",
    "main_study.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c495d4b-dae5-40cc-8e86-05d72c293d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add codes\n",
    "\n",
    "main_study = pd.merge(main_study, coded_data, on='doi', how='left', suffixes=('', '_from_df2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2718a16-0256-4d7c-9a7d-0cd80a13beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add altmetrics\n",
    "# Still need to get the data!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77f692ac-34bc-446b-9fac-8f26b00045b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract_text</th>\n",
       "      <th>pubyear</th>\n",
       "      <th>doctype</th>\n",
       "      <th>rater</th>\n",
       "      <th>block</th>\n",
       "      <th>field</th>\n",
       "      <th>ordinal</th>\n",
       "      <th>binary</th>\n",
       "      <th>group</th>\n",
       "      <th>rater_disc</th>\n",
       "      <th>nationality</th>\n",
       "      <th>sex</th>\n",
       "      <th>weird</th>\n",
       "      <th>field_group</th>\n",
       "      <th>abstract</th>\n",
       "      <th>chauvinism</th>\n",
       "      <th>present</th>\n",
       "      <th>intolerance</th>\n",
       "      <th>ethics</th>\n",
       "      <th>empirical</th>\n",
       "      <th>environment</th>\n",
       "      <th>fiction</th>\n",
       "      <th>education</th>\n",
       "      <th>wellbeing</th>\n",
       "      <th>deliverable</th>\n",
       "      <th>capture</th>\n",
       "      <th>citation</th>\n",
       "      <th>socialmedia</th>\n",
       "      <th>mention</th>\n",
       "      <th>outlier</th>\n",
       "      <th>usage</th>\n",
       "      <th>abstract_length</th>\n",
       "      <th>abstract_wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1080/09523367.2015.1022721</td>\n",
       "      <td>Does China Matter? Taiwan's Successful Bid to ...</td>\n",
       "      <td>This study seeks to identify and explain the k...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Article</td>\n",
       "      <td>151_main</td>\n",
       "      <td>QID1_1_main</td>\n",
       "      <td>History</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>main</td>\n",
       "      <td>History</td>\n",
       "      <td>Argentinian</td>\n",
       "      <td>M</td>\n",
       "      <td>not WEIRD</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>QID1_1_main_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1080/09523367.2015.1022721</td>\n",
       "      <td>Does China Matter? Taiwan's Successful Bid to ...</td>\n",
       "      <td>This study seeks to identify and explain the k...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Article</td>\n",
       "      <td>111_main</td>\n",
       "      <td>QID1_1_main</td>\n",
       "      <td>History</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>main</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>Serbian</td>\n",
       "      <td>M</td>\n",
       "      <td>not WEIRD</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>QID1_1_main_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1080/09523367.2015.1022721</td>\n",
       "      <td>Does China Matter? Taiwan's Successful Bid to ...</td>\n",
       "      <td>This study seeks to identify and explain the k...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Article</td>\n",
       "      <td>121_main</td>\n",
       "      <td>QID1_1_main</td>\n",
       "      <td>History</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>main</td>\n",
       "      <td>Linguistics</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>M</td>\n",
       "      <td>not WEIRD</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>QID1_1_main_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index                            doi  \\\n",
       "0             0.0  10.1080/09523367.2015.1022721   \n",
       "1             0.0  10.1080/09523367.2015.1022721   \n",
       "2             0.0  10.1080/09523367.2015.1022721   \n",
       "\n",
       "                                               title  \\\n",
       "0  Does China Matter? Taiwan's Successful Bid to ...   \n",
       "1  Does China Matter? Taiwan's Successful Bid to ...   \n",
       "2  Does China Matter? Taiwan's Successful Bid to ...   \n",
       "\n",
       "                                       abstract_text  pubyear  doctype  \\\n",
       "0  This study seeks to identify and explain the k...   2015.0  Article   \n",
       "1  This study seeks to identify and explain the k...   2015.0  Article   \n",
       "2  This study seeks to identify and explain the k...   2015.0  Article   \n",
       "\n",
       "      rater        block    field  ordinal  binary group   rater_disc  \\\n",
       "0  151_main  QID1_1_main  History      2.0     0.0  main      History   \n",
       "1  111_main  QID1_1_main  History      1.0     1.0  main   Philosophy   \n",
       "2  121_main  QID1_1_main  History      4.0     1.0  main  Linguistics   \n",
       "\n",
       "   nationality sex      weird field_group       abstract  chauvinism  present  \\\n",
       "0  Argentinian   M  not WEIRD  Humanities  QID1_1_main_1         1.0      1.0   \n",
       "1      Serbian   M  not WEIRD  Humanities  QID1_1_main_1         0.0      1.0   \n",
       "2      Turkish   M  not WEIRD  Humanities  QID1_1_main_1         0.0      1.0   \n",
       "\n",
       "   intolerance  ethics  empirical  environment  fiction  education  wellbeing  \\\n",
       "0          0.0     0.0        0.0          0.0      1.0        0.0        0.0   \n",
       "1          0.0     0.0        0.0          0.0      1.0        0.0        0.0   \n",
       "2          0.0     0.0        0.0          0.0      1.0        0.0        0.0   \n",
       "\n",
       "   deliverable  capture  citation  socialmedia  mention  outlier  usage  \\\n",
       "0          0.0      NaN       NaN          NaN      NaN      NaN    NaN   \n",
       "1          0.0      NaN       NaN          NaN      NaN      NaN    NaN   \n",
       "2          0.0      NaN       NaN          NaN      NaN      NaN    NaN   \n",
       "\n",
       "   abstract_length  abstract_wordcount  \n",
       "0              NaN                 NaN  \n",
       "1              NaN                 NaN  \n",
       "2              NaN                 NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine pilot data and main study\n",
    "combined_df = pd.concat([main_study, df], ignore_index=True, sort=False)\n",
    "\n",
    "# make all columns lower case\n",
    "combined_df.columns = combined_df.columns.str.lower()\n",
    "\n",
    "print(len(combined_df))\n",
    "combined_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1cc784b9-82c8-453f-9dd6-692b42f6abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# homogenize field term usage\n",
    "\n",
    "disc_names = {'HIST':'History','PHIL':'Philosophy','LING':'Linguistics','LIT':'Literature','REL':'Religion', 'Theology':'Religion'}\n",
    "combined_df = combined_df.replace(disc_names)\n",
    "\n",
    "# homogenize rater names\n",
    "combined_df['rater'] = combined_df['rater'].astype('str')\n",
    "combined_df['rater'] = [i.split('.')[0] for i in combined_df['rater'].values]\n",
    "\n",
    "# fix abstract length and word count\n",
    "\n",
    "combined_df['abstract_length'] = [len(i) for i in list(combined_df['abstract_text'].values)]\n",
    "combined_df['abstract_wordcount'] = [len(i.split(' ')) for i in combined_df['abstract_text'].values]\n",
    "\n",
    "# add useful columns\n",
    "\n",
    "combined_df['humanities'] = np.where(combined_df.field_group == 'Humanities',1,0)\n",
    "combined_df['new_rater_disc'] = combined_df.apply(lambda row: row['rater_disc'] if row['field_group'] == 'Humanities' else 'non-humanities', axis=1)\n",
    "combined_df['abstract_length_norm'] = (combined_df.abstract_length.values - combined_df.abstract_length.values.mean()) / np.std(combined_df.abstract_length.values)\n",
    "\n",
    "# dtypes\n",
    "int_cols = ['ordinal','binary','pubyear','chauvinism','present','intolerance','ethics',\n",
    "            'empirical','environment','fiction','education','wellbeing','deliverable']\n",
    "combined_df[int_cols] = combined_df[int_cols].astype('float64')\n",
    "combined_df[int_cols] = combined_df[int_cols].astype('Int64')\n",
    "\n",
    "cat_cols = ['sex','weird','rater','field','new_rater_disc', 'abstract','doctype']\n",
    "combined_df[cat_cols] = combined_df[cat_cols].astype('category')\n",
    "\n",
    "# create df for the main study\n",
    "\n",
    "df_main = combined_df.loc[combined_df.group == 'main'].copy()\n",
    "for col in cat_cols:\n",
    "    df_main[col] = df_main[col].cat.remove_unused_categories()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cea06693-8b63-4f6d-ad43-0d599ace2c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(r\"C:\\Users\\conix\\Dropbox\\aWriting\\humanities impact\\follow up study\\combined_data.csv\")\n",
    "df_main.to_csv(r\"C:\\Users\\conix\\Dropbox\\aWriting\\humanities impact\\follow up study\\df_main.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
