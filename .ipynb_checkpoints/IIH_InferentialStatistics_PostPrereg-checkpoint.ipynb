{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f7d076-af6a-440e-a378-a85db080b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import random\n",
    "import xarray as xr\n",
    "import itertools\n",
    "import pymc as pm\n",
    "from scipy.special import expit, logit\n",
    "import pytensor.tensor as pt\n",
    "from pymc.distributions.transforms import Ordered\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "\n",
    "import pymc as pm\n",
    "from scipy.special import expit, logit\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "collections.Mapping = collections.abc.Mapping\n",
    "collections.MutableSet = collections.abc.MutableSet\n",
    "collections.MutableMapping = collections.abc.MutableMapping\n",
    "from causalgraphicalmodels import CausalGraphicalModel\n",
    "import daft\n",
    "\n",
    "from scipy.special import expit, logit\n",
    "import pytensor.tensor as pt\n",
    "from pymc.distributions.transforms import Ordered\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec3d40-14f7-4f72-8aac-526b28c199ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650d44e-71b6-4f92-9f06-a10093b31658",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['sex','weird','rater','field','new_rater_disc', 'abstract','doctype']\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\conix\\Dropbox\\aWriting\\humanities impact\\follow up study\\combined_data.csv\", dtype = {i:'category' for i in cat_cols},  index_col=0)\n",
    "df_main = pd.read_csv(r\"C:\\Users\\conix\\Dropbox\\aWriting\\humanities impact\\follow up study\\df_main.csv\",dtype = {i:'category' for i in cat_cols}, index_col=0)\n",
    "\n",
    "\n",
    "content_codes = ['fiction','present', 'intolerance', 'ethics', 'empirical', 'environment','education', 'wellbeing', 'deliverable']\n",
    "content_params = content_codes +['doctype']\n",
    "\n",
    "fields_order = ['History','Philosophy','Religion','Linguistics','Literature']\n",
    "fields_names = ['History', 'Linguistics', 'Literature', 'Philosophy', 'Religion']\n",
    "rater_fields_names = ['History', 'Linguistics', 'Literature', 'Philosophy', 'Religion', 'non-humanities']\n",
    "\n",
    "print(f\"columns: {df.columns.values}\")\n",
    "print('')\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958aca1a-8669-4bc7-a50b-f6b47594a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do ordinal and binary data make sense?\n",
    "\n",
    "colors = ['r','b','g','c','orange']\n",
    "\n",
    "for i in range(5):\n",
    "    summed_scores = df.loc[df.field == df.field.unique()[i]].groupby('doi')[['binary','ordinal']].sum()\n",
    "\n",
    "    # add a bit of jitter to avoid overlap\n",
    "    jitter_amount = 0.2\n",
    "    x = summed_scores['binary'] + np.random.normal(0, jitter_amount, size=len(summed_scores))\n",
    "    y = summed_scores['ordinal'] + np.random.normal(0, jitter_amount, size=len(summed_scores))\n",
    "    \n",
    "    plt.scatter(x, y, s = 10,color = colors[i], alpha = 0.5)\n",
    "    \n",
    "plt.title('summed binary scores by summed ordinal scores')\n",
    "plt.legend(df.field.unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbaaf8-8d06-485d-adf3-4012c55030f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience function that we need later\n",
    "\n",
    "def linear_regr(X, Y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X.reshape(-1, 1), Y.reshape(-1, 1))\n",
    "    y_pred = model.predict(X.reshape(-1, 1))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf55ce12-c44d-495f-8931-d37a3e850fd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Causal assumptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4811b1-2a4e-4bf5-9243-3f8e3cb72112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check backdoor paths\n",
    "from tqdm import tqdm\n",
    "\n",
    "def backdoor(dag, predictor, outcome):\n",
    "    all_adjustment_sets = dag.get_all_backdoor_adjustment_sets(predictor, outcome)\n",
    "\n",
    "    for s in tqdm(all_adjustment_sets):\n",
    "        if all(not t.issubset(s) for t in all_adjustment_sets if t != s):\n",
    "            if s != {\"U\"}:\n",
    "                print(s)\n",
    "\n",
    "                \n",
    "def check_precisionvars(dag, var_of_interest, list_of_vars):\n",
    "    for i in list_of_vars:\n",
    "        if dag.is_valid_backdoor_adjustment_set(var_of_interest, \"binary\", {i}):\n",
    "            print(f\"Add {i} to the linear model for {var_of_interest}\")\n",
    "        else:\n",
    "            print(f\"Do not add {i} to the linear model for {var_of_interest}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02094b40-5c7c-4af9-aef1-683dc0c21c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_codes = ['content']\n",
    "outcome_vars = ['binary','ordinal']\n",
    "rater_props = ['chauvinism','GWH','rater_field','strictness','ideology','seniority']\n",
    "abstract_props = ['paper_value','field']\n",
    "interactions = ['content/field','content/GWH', 'content/ideology']\n",
    "other = ['estimate','altmetrics']\n",
    "\n",
    "content_edges = [('content', 'paper_value'),('field','content')]\n",
    "estimate_edges = [(i, 'estimate') for i in ['paper_value','chauvinism','content/field','content/GWH', 'content/ideology']]\n",
    "interaction_edges = [('rater_field','content_field'),('rater_field','content/field'),('content','content/field'),('content','content/GWH'),('GWH','content/GWH'),('ideology','content/ideology'),('rater_field','ideology'),('content','content/ideology')]\n",
    "other_edges = [('estimate','binary'),('strictness','binary'),('estimate','ordinal'),('field','chauvinism'),('rater_field','chauvinism'),('rater_field','GWH'),('field','paper_value'),('seniority','ideology'),('seniority','estimate'),('seniority','GWH')]\n",
    "\n",
    "altmetric_edges = [('paper_value','altmetrics'),('content','altmetrics'),('field','altmetrics')]\n",
    "\n",
    "nodes = content_codes + outcome_vars + rater_props + abstract_props + interactions + other \n",
    "edges = content_edges + estimate_edges + other_edges + interaction_edges+ altmetric_edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf585e21-c108-4328-910e-bc3fff14c7df",
   "metadata": {},
   "source": [
    "This is the updated causal model that we will use to decide which variables to include in the linear model of the thrustonian model (and in the logistic regression we run to double-check).\n",
    "\n",
    "To keep things more or less readable, we collaps all content codes into one in this one. The causal structure within these content codes is specified in contentDag below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c88aef-43a2-49ed-a6fa-0e00c6d4b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortDag = CausalGraphicalModel(\n",
    "    nodes=nodes, \n",
    "    edges=edges\n",
    "    \n",
    ")\n",
    "\n",
    "color_map = {'binary': 'lightblue','ordinal':'lightblue','estimate':'lightgrey','paper_value':'lightgrey',\n",
    "            'strictness':'lightgrey','field':'lightgreen','content':'lightgreen','GWH':'orange','rater_field':'orange','CONFOUNDER':'red','COLLIDER':'red','altmetrics':'lightblue', 'ideology':'orange','seniority':'orange'}\n",
    "\n",
    "\n",
    "shortDag.draw2(color_map=color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c998e491-0dfe-4625-87f3-0f3f61e2666e",
   "metadata": {},
   "source": [
    "Our main variables of interest:\n",
    "\n",
    "- Chauvinism\n",
    "- Strictness\n",
    "- Field\n",
    "- Content\n",
    "- intersting: Gender (or Weirdness)\n",
    "\n",
    "Based on the cell below, we need to add the following variables in our linear model in order to estimate the total causal effect of those particular variables. Note, these are the variables we need to add to get an estimate of the total causal effect. So, for 'field', the effects of content variables would be included as they are themselves caused by field.\n",
    "\n",
    "- CHAUVINISM: chauvinism, field and rater_field\n",
    "- field: field\n",
    "- content: content and field\n",
    "- Gender (or Weirdness): Gender (or Weirdness), seniority and rater_field. Given that we don't have data for seniority (everyone is a recent PhD), we have to keep in mind that our estimate for this may be biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de02aea-f334-489d-9f53-67fac6268439",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['paper_value',]: # 'chauvinism','field','content','GWH'\n",
    "    print( f\"{i}:\" )\n",
    "    backdoor(shortDag,i,'binary')\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef433e27-3963-4c32-847e-ad3f5deeaf3e",
   "metadata": {},
   "source": [
    "These DAGs collaps all content variables. However, these too have an internal causal structure. More precisely, there is a relation between recent, empirical and deliverable. We assume they are related to each other, and to the outcome variables, as illustrated below. The implication of this is that to get the total causal effect of deliverable and empirical, we cannot control for present. To get the total causal effect of present, we have to control for deliverable and empirical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c45bb0-efa4-42a5-8c1a-9dbb13119b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contentDag = CausalGraphicalModel(\n",
    "    nodes=['present','empirical','estimate','binary','paper_value', 'deliverable','ordinal'], \n",
    "    edges=[('deliverable','present'),('deliverable','paper_value'),('empirical','present'),('present','paper_value'),('empirical','paper_value'),('estimate','binary'),('estimate','ordinal'), ('paper_value','estimate')]\n",
    "    \n",
    ")\n",
    "\n",
    "color_map = {'binary': 'lightblue','ordinal':'lightblue','estimate':'lightgrey','paper_value':'lightgrey',\n",
    "            'deliverable':'lightgreen','empirical':'lightgreen','present':'lightgreen'}\n",
    "\n",
    "\n",
    "contentDag.draw2(color_map=color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484545d-1173-434e-86ab-f3ddeeb9cdf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in ['deliverable','empirical','present']:\n",
    "    print( f\"{i}:\" )\n",
    "    backdoor(contentDag,i,'binary')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7dd84-ca94-4b4e-875d-a327c43174d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for colinearity by looking at Variance Inflation Factor (VIF)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from patsy import dmatrices\n",
    "\n",
    "# Your model formula\n",
    "formula = 'binary ~ empirical + deliverable + present'\n",
    "\n",
    "# Get the design matrix\n",
    "_, X = dmatrices(formula, df, return_type='matrix')\n",
    "\n",
    "# Calculate VIF for each explanatory variable\n",
    "vif = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d6bf19-b6b8-4127-84b6-9b2cf5c505f3",
   "metadata": {},
   "source": [
    "Of course, we can add variables to the linear model to make the estimate of the causal effects more precise. We have to be careful not to open any backdoor paths or to estimate partial causal effects. So check for that first. In short, for chauvinism and content we cannot add any other variables that we have. For field, we could add gender, weirdness and rater_field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c0a866-7d10-4c52-a798-0520bce087e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = ['field','rater_field','chauvinism','content/field','content/GWH','GWH','content/ideology','ideology','content']\n",
    "\n",
    "print('For chauvinism:')\n",
    "print('')\n",
    "\n",
    "check_precisionvars(shortDag, 'chauvinism', controls[3:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b0b592-ed13-449e-8525-67c6d8e92062",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For field:')\n",
    "print('')\n",
    "\n",
    "check_precisionvars(shortDag, 'field', controls[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a23c8-2fc7-4484-af5e-8afbee4538d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For content:')\n",
    "print('')\n",
    "\n",
    "check_precisionvars(shortDag, 'content', controls[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d05b47c-c0c1-47d3-9f87-13b92033273c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Separate regressions\n",
    "\n",
    "Start with a quick look at the associations between each of the variables and the binary outcome variable. This is not particularly meaningful, given that it doesn't take into account how these variables are causally related (i.e. the DAG). Still, it is good to have have an idea of what seems associated with what in some way or another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc59cfc-54e3-4adc-aac3-78f63345f1f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d38562-394b-4738-b259-952546807c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['doctype','field_group','rater_disc','sex','weird','group','field','chauvinism'] + content_codes # rater\n",
    "\n",
    "df_simpleregs = df[cat_vars + ['binary','ordinal']].copy()\n",
    "\n",
    "# create new rater disc column to put all non-hum in one rater_disc\n",
    "df_simpleregs['new_rater_disc'] = df_simpleregs.apply(lambda row: row['rater_disc'] if row['field_group'] == 'Humanities' else 'non-humanities', axis=1)\n",
    "\n",
    "# one-hot encode rater_disc and field\n",
    "\n",
    "columns_to_encode = ['new_rater_disc', 'field']\n",
    "\n",
    "# One-hot encode specific columns and join back to the original DataFrame\n",
    "df_simpleregs = pd.get_dummies(df_simpleregs, columns=columns_to_encode)\n",
    "\n",
    "# create lists of vars for the regressions\n",
    "\n",
    "all_data_regs = ['doctype', 'field_group',  \n",
    "       'chauvinism', 'present', 'intolerance', 'ethics',\n",
    "       'empirical', 'environment', 'education', 'wellbeing', 'deliverable',\n",
    "        'new_rater_disc_History',\n",
    "       'new_rater_disc_Linguistics', 'new_rater_disc_Literature',\n",
    "       'new_rater_disc_Philosophy', 'new_rater_disc_Religion',\n",
    "       'new_rater_disc_non-humanities', 'field_History', 'field_Linguistics',\n",
    "       'field_Literature', 'field_Philosophy', 'field_Religion']\n",
    "\n",
    "main_study_regs = ['fiction','sex', 'weird', 'doctype', 'field_group', \n",
    "       'chauvinism', 'present', 'intolerance', 'ethics',\n",
    "       'empirical', 'environment', 'education', 'wellbeing', 'deliverable',\n",
    "       'new_rater_disc_History','new_rater_disc_Linguistics', 'new_rater_disc_Literature',\n",
    "       'new_rater_disc_Philosophy', 'new_rater_disc_Religion',\n",
    "       'new_rater_disc_non-humanities', 'field_History', 'field_Linguistics',\n",
    "       'field_Literature', 'field_Philosophy', 'field_Religion']\n",
    "\n",
    "# coordinates for the models\n",
    "\n",
    "set_both = list(set(all_data_regs).union(set(main_study_regs)))\n",
    "\n",
    "df_simpleregs[set_both] = df_simpleregs[set_both].astype('category')\n",
    "\n",
    "# change categories to ints\n",
    "\n",
    "for column in set_both:\n",
    "    df_simpleregs[column] = df_simpleregs[column].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d38f02-fa65-4f7c-99cc-8016d34d1a22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## All variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d851ec-d22e-4586-a1c1-1a3173dd85f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data, without the the variables that were not included in the pilots\n",
    "\n",
    "coords = {'codes': all_data_regs}\n",
    "with pm.Model(coords=coords) as modelA:\n",
    "\n",
    "    data = pm.MutableData('data', df_simpleregs[all_data_regs].values)\n",
    "    \n",
    "    vars = pm.Normal('vars',0,1, dims = 'codes')\n",
    "    intercept = pm.Normal('intercept', 0,1)\n",
    "\n",
    "    p = pm.invlogit(intercept + vars * data) \n",
    "    \n",
    "    # Bernoulli random vector with probability of relevant\n",
    "    for i,code in enumerate(all_data_regs):\n",
    "        logit = pm.Bernoulli(name=f'logit_{code}', p=p[:,i], observed=df_simpleregs.binary.values)\n",
    "\n",
    "    trace_modelA = pm.sample(300, tune = 100)\n",
    "\n",
    "coords = {'codes': main_study_regs}\n",
    "\n",
    "# main study, with all variables\n",
    "with pm.Model(coords=coords) as modelM:\n",
    "\n",
    "    data = pm.MutableData('data', df_simpleregs.loc[df_simpleregs['group'] == 'main'][main_study_regs].values)\n",
    "    \n",
    "    vars = pm.Normal('vars',0,1, dims = 'codes')\n",
    "    intercept = pm.Normal('intercept', 0,1)\n",
    "\n",
    "    p = pm.invlogit(intercept + vars * data) \n",
    "    \n",
    "    # Bernoulli random vector with probability of relevant\n",
    "    for i,code in enumerate(main_study_regs):\n",
    "        logit = pm.Bernoulli(name=f'logit_{code}', p=p[:,i], observed=df_simpleregs.loc[df_simpleregs['group'] == 'main'].binary.values)\n",
    "\n",
    "    trace_modelM = pm.sample(300, tune = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde0739-104e-4402-b70c-32d505ad4711",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_modelM.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_modelM.nc\")\n",
    "trace_modelA.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_modelA.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b1dee-ec3e-4da7-a956-063b819f9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the traces\n",
    "\n",
    "trace_modelM = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_modelM.nc\")\n",
    "trace_modelA = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_modelA.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb327d-239d-4f7a-a073-81833c70ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(figsize = (12,15))\n",
    "\n",
    "t1 = trace_content_all.posterior['content_vars'].loc[:,:,all_data_regs]\n",
    "t2 = trace_content_main.posterior['content_vars'].loc[:,:,all_data_regs ]\n",
    "\n",
    "az.plot_forest([t1,t2], \n",
    "               model_names = ['all data', 'main study'], \n",
    "              \n",
    "               combined = True,\n",
    "              ax=ax)\n",
    "\n",
    "ax.axvline(0, c = 'green')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ba2d7-4e46-46df-80a0-8dca091e1edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also plot variables that were not available for all data (so this is only main study)\n",
    "\n",
    "az.plot_forest(trace_content_main.posterior['content_vars'].loc[:,:,['weird','fiction','sex'] ], combined = True)\n",
    "plt.show()\n",
    "\n",
    "print('for gender, 1 == M')\n",
    "print('for WEIRD, 1 == not WEIRD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fff5fd-23fd-4a7b-b6e4-d12dea3a8b6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Abstract length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d8691-a777-4414-83f8-fa671c56c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract length\n",
    "\n",
    "with pm.Model() as abstract_lengthA:\n",
    "    data = pm.MutableData('data',df.abstract_length_norm.values)\n",
    "    intercept = pm.Normal('intercept',0,1)\n",
    "    abstract_length = pm.Normal('abstract_length',0,1)\n",
    "    p = pm.invlogit(intercept + abstract_length * data) \n",
    "    logit = pm.Bernoulli(name='logit', p=p, observed=df.binary.values)\n",
    "    trace_alA = pm.sample(1000)\n",
    "\n",
    "with pm.Model() as abstract_lengthM:\n",
    "    data = pm.MutableData('data',df.loc[df['group'] == 'main'].abstract_length_norm.values)\n",
    "    intercept = pm.Normal('intercept',0,1)\n",
    "    abstract_length = pm.Normal('abstract_length',0,1)\n",
    "    p = pm.invlogit(intercept + abstract_length * data) \n",
    "    logit = pm.Bernoulli(name='logit', p=p, observed=df.loc[df['group'] == 'main'].binary.values)\n",
    "    trace_alM = pm.sample(1000)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c026e-3dfc-4295-beaf-4cd0524a0729",
   "metadata": {},
   "source": [
    "Different model for abstract length, as it is a continuous variable. Interpretation: a positive value means that an increase in abstract length comes with a higher probability of a binary score of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da42068-3aae-4c72-903d-a5ca1685b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = 1, figsize = (5,3))\n",
    "\n",
    "az.plot_forest([trace_alA, trace_alM], \n",
    "               model_names = ['all data', 'main study'], \n",
    "               var_names = 'abstract_length',\n",
    "               combined = True, ax=ax)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faafaf3-933f-4083-a462-5ffa93f5a0b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Multivariate logistic regressions\n",
    "\n",
    "Now run logistic regressions that include multiple predictor variables at once. Which ones to include has been decided using the DAG at the start of this notebook, i.e. we check which ones we have to (and can) include to estimate the effect of the variable of interest, appropriately closing backdoor paths and not opening any.\n",
    "\n",
    "Because including 'Present' in the content codes would bias 'deliverable' and 'empirical' (according to our DAG), we leave it out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c17218e-8d28-4962-98f1-bea71e9486ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'present' from the content codes\n",
    "\n",
    "content_codes = ['fiction', 'intolerance', 'ethics', 'empirical', 'environment','education', 'wellbeing', 'deliverable']\n",
    "content_params = content_codes +['doctype']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760e63f-3cca-442b-bb80-b3437acf4e44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Estimate the causal effect of chauvinism\n",
    "\n",
    "Variables to include: chauvinism, field and rater_field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d283ff7-d2ef-400c-a9d8-5bdbe6f2c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[(df.group == 'group1')]['rater']).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf21d7-3c07-4e50-8f4c-7458ed2609f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['field'] = df.field.astype('category')\n",
    "df['new_rater_disc'] = df.new_rater_disc.astype('category')\n",
    "df['abstract'] = df['abstract'].astype('category')\n",
    "df['rater'] = df.rater.astype('category')\n",
    "coords = { 'fields_c':fields_names, 'rater_fields_c': rater_fields_names, 'abstracts_c' :df['abstract'].cat.categories,\n",
    "'raters_c': df['rater'].cat.categories}\n",
    "\n",
    "with pm.Model(coords=coords) as chauvinism_model_all:\n",
    "\n",
    "    FIELD = pm.MutableData('FIELD', df.field.astype('category').cat.codes.values)\n",
    "    RATER_FIELD = pm.MutableData('RATER_FIELD', df.new_rater_disc.astype('category').cat.codes.values)\n",
    "    CHAUVINISM = pm.MutableData('CHAUVINISM', df.chauvinism.values)\n",
    "    ABSTRACT = pm.MutableData('ABSTRACT', df['abstract'].cat.codes.values)\n",
    "    RATER = pm.MutableData('RATER', df['rater'].cat.codes.values)\n",
    "\n",
    "    intercept = pm.Normal('intercept',0,1, dims = 'abstracts_c')\n",
    "    field = pm.Normal('field', 0,1, dims = 'fields_c')\n",
    "    rater_field = pm.Normal('rater_field', 0,1, dims = 'rater_fields_c')\n",
    "    chauvinism = pm.Normal('chauvinism',0,1, dims = 'raters_c')\n",
    "    strictness = pm.Normal('strictness',0,1,dims = 'raters_c')    \n",
    "\n",
    "    lm = intercept[ABSTRACT] +  field[FIELD] + rater_field[RATER_FIELD] + strictness[RATER] + chauvinism[RATER] * CHAUVINISM\n",
    "    y = pm.Bernoulli('y', logit_p = lm, observed = df['binary'].values)\n",
    "    trace_chauvinism_model_all = pm.sample(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360c9ba-4991-4ac7-ba10-5ef700bc9d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_chauvinism_model_all.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_chauvinism_model_all.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928335bc-e851-4cef-88aa-4aa157c3aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_chauvinism_model_all = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_chauvinism_model_all.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988fe05b-4783-41f7-b0a1-196da3b97808",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (7,10))\n",
    "az.plot_forest(trace_chauvinism_model_all, var_names = ['chauvinism'],combined = True,ax=ax)\n",
    "ax.axvline(0, color = 'black')\n",
    "plt.show()\n",
    "print(\"raters group 1: ['521', '142', '421', '511', '311', '211', '321', '121', '111']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b89a8c-5560-4428-ac37-921f5f7d7531",
   "metadata": {},
   "source": [
    "## Estimate the causal effect of field\n",
    "\n",
    "Variables to include: just field (for more precision, it would be harmless to add rater_field and gender and weirdness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c556b0f-f04f-459f-a2cb-65ab3147ef24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9c031-7a7a-4eee-ace7-870ba14ce414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'] = df.sex.astype('category')\n",
    "df['weird'] = df.weird.astype('category')\n",
    "df['abstract'] = df['abstract'].astype('category')\n",
    "df['rater'] = df.rater.astype('category')\n",
    "df['new_rater_disc'] = df.new_rater_disc.astype('category')\n",
    "\n",
    "coords = { 'fields_c':fields_names, 'rater_fields_c': rater_fields_names, 'weird_c': ['not weird','weird'], 'gender_c':['female','male'] , 'abstracts_c' :df['abstract'].cat.categories, 'raters_c': df['rater'].cat.categories}\n",
    "\n",
    "with pm.Model(coords=coords) as field_model:\n",
    "\n",
    "    FIELD = pm.MutableData('FIELD', df.field.astype('category').cat.codes.values)\n",
    "    GENDER = pm.MutableData('GENDER', df.sex.astype('category').cat.codes.values)\n",
    "    WEIRD = pm.MutableData('WEIRD', df.weird.astype('category').cat.codes.values)\n",
    "    ABSTRACT = pm.MutableData('ABSTRACT', df['abstract'].cat.codes.values)\n",
    "    RATER = pm.MutableData('RATER', df['rater'].cat.codes.values)\n",
    "    RATER_FIELD = pm.MutableData('RATER_FIELD', df.new_rater_disc.astype('category').cat.codes.values)\n",
    "\n",
    "    \n",
    "    intercept = pm.Normal('intercept',0,1, dims = 'abstracts_c')\n",
    "    fields = pm.Normal('fields', 0,1, dims = 'fields_c')\n",
    "    gender = pm.Normal('gender', 0,1, dims = 'gender_c')\n",
    "    weird = pm.Normal('weird',0,1, dims = 'weird_c')\n",
    "    rater_field = pm.Normal('rater_field', 0,1, dims = 'rater_fields_c')\n",
    "    strictness = pm.Normal('strictness',0,1,dims = 'raters_c')    \n",
    "\n",
    "\n",
    "    lm = intercept[ABSTRACT] + field[FIELD] + rater_field[RATER_FIELD] + gender[GENDER] + weird[WEIRD] + strictness[RATER]\n",
    "    y = pm.Bernoulli('y', logit_p = lm, observed = df['binary'].values)\n",
    "\n",
    "    trace_field_model_all = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efecf5f7-fc2f-4190-9df1-6bdca4325186",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_field_model_all.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_field_model_all.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c868b-ea98-48ec-8810-8a183495b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_field_model_all = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_field_model_all.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c4e19-2c7b-4840-bfff-4dfef3f22a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(trace_field_model_all, var_names = ['field'], combined = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7345d3-54b1-4c52-8144-2c94241f6100",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Main study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f245b8-f831-44a5-a55c-7f16e33f9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['sex'] = df_main.sex.astype('category')\n",
    "df_main['weird'] = df_main.weird.astype('category')\n",
    "df_main['abstract'] = df_main['abstract'].astype('category')\n",
    "df_main['rater'] = df_main.rater.astype('category')\n",
    "df_main['new_rater_disc'] = df_main.new_rater_disc.astype('category')\n",
    "\n",
    "coords = { 'fields_c':fields_names, 'rater_fields_c': rater_fields_names, 'weird_c': ['not weird','weird'], 'gender_c':['female','male'] , 'abstracts_c' :df_main['abstract'].cat.categories, 'raters_c': df_main['rater'].cat.categories}\n",
    "\n",
    "with pm.Model(coords=coords) as field_model:\n",
    "\n",
    "    FIELD = pm.MutableData('FIELD', df_main.field.astype('category').cat.codes.values)\n",
    "    GENDER = pm.MutableData('GENDER', df_main.sex.astype('category').cat.codes.values)\n",
    "    WEIRD = pm.MutableData('WEIRD', df_main.weird.astype('category').cat.codes.values)\n",
    "    ABSTRACT = pm.MutableData('ABSTRACT', df_main['abstract'].cat.codes.values)\n",
    "    RATER = pm.MutableData('RATER', df_main['rater'].cat.codes.values)\n",
    "    RATER_FIELD = pm.MutableData('RATER_FIELD', df_main.new_rater_disc.astype('category').cat.codes.values)\n",
    "\n",
    "    \n",
    "    intercept = pm.Normal('intercept',0,1, dims = 'abstracts_c')\n",
    "    fields = pm.Normal('fields', 0,1, dims = 'fields_c')\n",
    "    gender = pm.Normal('gender', 0,1, dims = 'gender_c')\n",
    "    weird = pm.Normal('weird',0,1, dims = 'weird_c')\n",
    "    rater_field = pm.Normal('rater_field', 0,1, dims = 'rater_fields_c')\n",
    "    strictness = pm.Normal('strictness',0,1,dims = 'raters_c')    \n",
    "\n",
    "\n",
    "    lm = intercept[ABSTRACT] + fields[FIELD] + rater_field[RATER_FIELD] + gender[GENDER] + weird[WEIRD] + strictness[RATER]\n",
    "    y = pm.Bernoulli('y', logit_p = lm, observed = df_main['binary'].values)\n",
    "\n",
    "    trace_field_model = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af31839a-c478-4b8e-93b8-5650f770eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_field_model.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_field_model2.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63438d8-55d9-4383-9308-10144c4ef8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_field_model = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_field_model2.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa07503-9ad3-4793-9946-ed651bcef400",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(trace_field_model, var_names = ['fields'], combined = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179ed6b8-70f4-403b-86dd-f918930250f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Content\n",
    "\n",
    "We cannot check all content variables at once. Because including 'present' would bias the other variables, we omit it here. For now I omit fiction, but that will be added as soon as we have the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e0ed81-f216-44cd-99c8-b769e384497e",
   "metadata": {},
   "source": [
    "### All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe42c2-9041-4ed4-b0f2-390d34eb2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rater'] = df.rater.astype('category').values\n",
    "df['abstract'] = df['abstract'].astype('category').values\n",
    "\n",
    "coords = {'fields_c':fields_names,'bin_c': content_params}\n",
    "J = len(df['rater'].unique())\n",
    "\n",
    "# have to sort by group first, to make sure I can compare with the thurstonian model, where they are analysed separately\n",
    "df = df.sort_values(by = ['group','block','abstract','rater'])\n",
    "with pm.Model(coords=coords) as content_model_all:\n",
    "\n",
    "    # content codes without fiction\n",
    "    BIN_DATA = pm.MutableData('BIN_DATA', df[content_params].values)\n",
    "    FIELD = pm.MutableData('FIELD', df.field.astype('category').cat.codes.values)\n",
    "    RATER = pm.MutableData('RATER', df['rater'].cat.codes.values)\n",
    "    ABSTRACT = pm.MutableData('ABSTRACT', df['abstract'].cat.codes.values)\n",
    "    \n",
    "    content = pm.Normal('content',0,1, dims = 'bin_c')\n",
    "    intercept = pm.Normal('intercept',0,1, shape = len(df['abstract'].unique())) \n",
    "    field = pm.Normal('field', 0,1, dims = 'fields_c')\n",
    "    strictness = pm.Normal('strictness',0,1,shape = (J))\n",
    "    lm = intercept[ABSTRACT] + pt.dot(BIN_DATA, content) + field[FIELD] + strictness[RATER]\n",
    "    y = pm.Bernoulli('y', logit_p = lm, observed = df['binary'].values)\n",
    "\n",
    "    trace_content_model_all = pm.sample(3000, tune = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4fe98e-a120-4561-b77a-85e231e678cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_content_model_all.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_content_model_all.nc\")\n",
    "# trace_noncontentM.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\noncontentM.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0398c9-4acc-47f6-92fc-c3a3ed65c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_content_model_all = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_content_model_all.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677b4b8c-fac3-455c-88ff-7b9ac2d92289",
   "metadata": {},
   "source": [
    "### main study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144cbb21-e2e2-4242-824a-914dd3e4d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz = df.loc[df.group == 'main'].copy()\n",
    "mData = prep_data_thurston(df, 'main')\n",
    "dfz['rater'] = dfz.rater.astype('category').values\n",
    "\n",
    "coords = {'fields_c':fields_names,'bin_c': content_params}\n",
    "J = len(df.loc[df.group == 'main']['rater'].unique())\n",
    "with pm.Model(coords=coords) as content_model:\n",
    "\n",
    "    CONTENT = pm.MutableData('CONTENT', mData['content_presence'])\n",
    "    RATER = pm.MutableData('RATER', dfz.loc[df.group == 'main']['rater'].cat.codes.values)\n",
    "    content = pm.Normal('content',0,1,shape = (len(content_params)))\n",
    "    dot_prod = pt.dot(CONTENT, content)\n",
    "    dot_prod_reshaped = dot_prod.reshape((B,K))\n",
    "\n",
    "    fields = pm.Normal('fields',0, 1,shape = (K))\n",
    "\n",
    "    # should this have an intercept that is different for each paper?\n",
    "    paper_intercepts = pm.Normal('paper_intercepts',0,1,shape = (B,K)) # shape = (B,K)\n",
    "\n",
    "    paper_values = pm.Deterministic('paper_values', paper_intercepts + fields[mData['fields_presence']] + dot_prod_reshaped)\n",
    "\n",
    "    # add the chauvinism parameter to the linear model (and index it to make sure it works for the correct papers)\n",
    "    mu = pm.Deterministic('mu', pt.tile(paper_values[:,pt.newaxis,:],(1,J,1)))\n",
    "    mu = pt.flatten(mu)\n",
    "    strictness = pm.Normal('strictness',0,1,shape =len(df.loc[df.group == 'main']['rater'].unique()))\n",
    "    binary = pm.Bernoulli('binary',logit_p = mu + strictness[RATER], observed = np.ravel(mData['binary_data']))\n",
    "    trace_content_model = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e830efe-aab2-4331-b6ab-da0657b25936",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_content_model.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_content_model.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f326f2-c49c-445e-98db-a6b6a826a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_content_model = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_content_model.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17f469-7d42-43bc-866a-86ea4998449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest([trace_content_model_all,trace_content_model], model_names = ['All', 'Main study'],var_names = 'content', combined = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2060aa85-093e-4aa0-b499-9b6b51daa5c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Thurstonian Model: Data preparation\n",
    "\n",
    "Note: We tested both models with a different intercept for each paper, and models with a single intercept. The ones with the varying intercept clearly outperformed the ones with the fixed intercept on common metrics for model comparison. This is to be expected, as we expect the value of the papers (beyond what can be captured by the parameters we have) to vary widely. The varying paper intercept captures this difference between papers beyond the field and content parameters. We also tested adding a hyperprior for the sd of paper_intercepts, but this did not change model performance or outcomes significantly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48d5df9-ba6c-4787-a68b-7b153399662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if value is integer and replace if not\n",
    "\n",
    "K = 5\n",
    "\n",
    "def replace_non_integers_in_column(value, replacement):\n",
    "    if isinstance(value, int):\n",
    "        return value\n",
    "    else:\n",
    "        return replacement\n",
    "        \n",
    "# turn df into usable data and indexing for the model\n",
    "def prep_data_thurston(df, group):\n",
    "    \n",
    "    out = {}\n",
    "    # get the data from the main study\n",
    "\n",
    "    dfm = df.loc[df.group == group].sort_values(['block','abstract','rater']).copy()\n",
    "\n",
    "    J = len(dfm.rater.unique())\n",
    "    B = len(dfm.block.unique())\n",
    "    \n",
    "    # data for the content parameters\n",
    "    if 'doctype' in dfm.columns:\n",
    "        dfm['doctype'] = dfm['doctype'].cat.codes\n",
    "    content_df = dfm.drop_duplicates(subset = 'doi')[content_params+['block','abstract','field']].sort_values(['block','abstract']).copy()\n",
    "    content_presence = content_df[content_params].values\n",
    "    \n",
    "    out['content_presence'] = content_presence\n",
    "    \n",
    "    # data for the fields\n",
    "    fields_order = ['History','Philosophy','Religion','Linguistics','Literature']\n",
    "    fields_presence = np.tile(np.arange(K), (B, 1))\n",
    "\n",
    "    out['fields_presence'] = fields_presence\n",
    "    \n",
    "    # get chauvinism data\n",
    "    \n",
    "    rater_fields = dfm.drop_duplicates(subset='rater')[['rater','rater_disc']].sort_values('rater')\n",
    "    rater_fields = rater_fields.replace({'History':0, 'Philosophy':1, 'Religion':2,'Linguistics':3, 'Literature':4})\n",
    "    \n",
    "    \n",
    "            \n",
    "    rater_fields['rater_disc'] = rater_fields['rater_disc'].apply(lambda x: replace_non_integers_in_column(x,5))\n",
    "    rater_fields_dct = {rater_fields['rater'].values[i] : rater_fields['rater_disc'].values[i] for i in range(len(rater_fields))}\n",
    "    \n",
    "    chauv_array = np.zeros((B, J, K), dtype=int)\n",
    "    for i in range(J):\n",
    "        if rater_fields['rater_disc'].values[i] < 5:\n",
    "            chauv_array[:, i, rater_fields['rater_disc'].values[i]] = 1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    out['chauv_array'] = chauv_array\n",
    "\n",
    "    # rater fields\n",
    "    categories = ['History', 'Philosophy', 'Linguistics', 'Literature', 'Religion','Non-humanities']\n",
    "\n",
    "    dfm['CategoricalColumn'] = pd.Categorical(dfm['new_rater_disc'], categories=categories)\n",
    "    dfm['codes'] = dfm['CategoricalColumn'].cat.codes\n",
    "\n",
    "    discs = dfm[['rater','codes','doi']].drop_duplicates(subset = 'rater')['codes']\n",
    "    array_2D = np.array([np.full(K, disc) for disc in discs.values])\n",
    "    rater_fields = np.tile(array_2D, (B, 1, 1))\n",
    "\n",
    "    out['rater_fields'] = rater_fields\n",
    "    \n",
    "    # get the rank data\n",
    "    \n",
    "    rank_data = dfm.pivot_table(index=['block', 'rater'], columns='field', values='ordinal', aggfunc='first').reset_index()\n",
    "    rank_data = rank_data.sort_values(['block','rater'], ascending = True) #\n",
    "    block_order = rank_data['block'].unique()\n",
    "    rank_data = rank_data[fields_order].values.reshape(B,J,K)\n",
    "    rank_data_argsort = np.argsort(rank_data) \n",
    "\n",
    "    out['rank_data'] = rank_data.astype('int32')\n",
    "    out['rank_data_argsort'] = rank_data_argsort.astype('int32')\n",
    "    \n",
    "    # get the binary data\n",
    "    \n",
    "    binary_data = dfm.pivot_table(index=['block', 'rater'], columns='field', values='binary', aggfunc='first').reset_index()\n",
    "    binary_data = binary_data.sort_values(['block','rater'], ascending = True) #\n",
    "    binary_data = binary_data[fields_order].values.reshape(B,J,K)\n",
    "\n",
    "    out['binary_data'] = binary_data\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff89730-bac4-4bd8-b8e4-577e4a9e8427",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Content: Fields and content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6717d-3d08-4337-b636-9a6904bf10a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Main study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b8467-a980-43b9-a01b-c1bbda032690",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prep data and counts to be used in the model\n",
    "\n",
    "# numbers of humanities and non-humanities raters. Important because non-humanities raters have no chauvinism parameter.\n",
    "J_hum = 11\n",
    "J_non_hum = 11\n",
    "\n",
    "# number of fields\n",
    "K = 5\n",
    "\n",
    "mData = prep_data_thurston(df, 'main')\n",
    "\n",
    "# number of sets\n",
    "B = 30\n",
    "\n",
    "# total number of raters\n",
    "J = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd3e3d-c590-45a5-a686-8a411eb88233",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as content_thurstonian:\n",
    "\n",
    "\n",
    "    CONTENT = pm.MutableData('CONTENT', mData['content_presence'])\n",
    "    \n",
    "    content = pm.Normal('content',0,1,shape = (len(content_params)))\n",
    "    dot_prod = pt.dot(CONTENT, content)\n",
    "    dot_prod_reshaped = dot_prod.reshape((B,K))\n",
    "\n",
    "    fields = pm.Normal('fields',0, 1,shape = (K))\n",
    "\n",
    "    # should this have an intercept that is different for each paper?\n",
    "    paper_intercepts = pm.Normal('paper_intercepts',0,1,shape = (B,K)) \n",
    "\n",
    "    paper_values = pm.Deterministic('paper_values', paper_intercepts + fields[mData['fields_presence']] + dot_prod_reshaped)\n",
    "\n",
    "    # add the chauvinism parameter to the linear model (and index it to make sure it works for the correct papers)\n",
    "    mu = pm.Deterministic('mu', pt.tile(paper_values[:,pt.newaxis,:],(1,J,1)))\n",
    "\n",
    "    reordered_mu = pm.Deterministic('reordered_mu', pt.take_along_axis(mu, mData['rank_data_argsort'], axis = -1))\n",
    "    sigma = pm.Uniform('sigma',0.01,2)\n",
    "    latent = pm.Normal('latent',\n",
    "                       mu=reordered_mu,\n",
    "                       sigma=sigma, \n",
    "                       transform=Ordered(), \n",
    "                       shape=(B,J,K),\n",
    "                       # have to set test value to avoid issues with negative numbers\n",
    "                       testval=np.tile(np.tile(np.arange(K), (B, 1))[:, np.newaxis, :], (1, J, 1))) \n",
    "\n",
    "    latent_reshaped = pt.take_along_axis(latent, mData['rank_data'], axis = -1)\n",
    "\n",
    "\n",
    "    strictness = pm.Normal('strictness',0,1,shape = (1,J,1))\n",
    "    binary = pm.Bernoulli('binary',logit_p = latent_reshaped + strictness, observed = mData['binary_data'])\n",
    "    pr6 = pm.sample_prior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c6331-0685-4959-a1fd-4f5ff40df257",
   "metadata": {},
   "outputs": [],
   "source": [
    "with content_thurstonian:\n",
    "    trace_content_thurstonian = pm.sample(3000, tune = 1000, idata_kwargs={\"log_likelihood\": True},target_accept = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12d939-c907-40f7-a89a-f9a1099b8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_content_thurstonian.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_content_thurstonian.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5aba7-559d-432d-a3ea-e5aa730ea7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_content_thurstonian = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_content_thurstonian.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68efc093-60ff-4a7a-91ed-8f79f6220f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check association between estimated values and reviewer scores\n",
    "\n",
    "def standardize(data):\n",
    "    out = (data - data.mean()) / np.std(data)\n",
    "    return out\n",
    "fig, ax = plt.subplots(ncols = 3, figsize = (16,4))\n",
    "\n",
    "## estimated values by reviewer scores\n",
    "mpaper_means = np.ravel(trace_content_thurstonian.posterior['paper_values'].mean(dim = ['chain','draw']).values)\n",
    "\n",
    "# normalize reviewer scores so binary and ordinal are on the same scale\n",
    "binary_sums = standardize(np.ravel(mData['binary_data'].sum(axis = 1)))\n",
    "ordinal_sums = standardize(np.ravel(mData['rank_data'].sum(axis = 1)))\n",
    "ax[2].scatter(y = binary_sums, x = mpaper_means, color = 'r', alpha = 0.3)\n",
    "ax[2].scatter(y = ordinal_sums, x = mpaper_means, color = 'b', alpha = 0.3)\n",
    "ax[2].legend(['binary sums','ordinal sums'])\n",
    "ax[2].set_title('Estimated value by reviewer scores')\n",
    "\n",
    "mscores = df.loc[df.group == 'main'].sort_values(['block','abstract']).groupby('abstract')[['ordinal','binary']].sum().values\n",
    "\n",
    "\n",
    "\n",
    "## regressions\n",
    "\n",
    "y_ord = linear_regr(mpaper_means, mscores[:,0])\n",
    "y_bin = linear_regr(mpaper_means, mscores[:,1])\n",
    "\n",
    "sns.scatterplot(y = mscores[:,0], x = mpaper_means, ax=ax[0])\n",
    "ax[0].plot(mpaper_means, y_ord, color = 'r')\n",
    "ax[0].set_title('Regression estimated scores and ordinal scores')\n",
    "\n",
    "sns.scatterplot(y = mscores[:,1], x = mpaper_means, ax=ax[1])\n",
    "ax[1].plot(mpaper_means, y_bin, color = 'r')\n",
    "ax[1].set_title('Regression estimated scores and binary scores')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98bf0cb-5a83-4cb5-a3b3-e4355b599057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check difference thurstonian model and logistic regression\n",
    "# I standardize first, because they are not on the same scale\n",
    "\n",
    "trace_content_thurstonian.posterior['content_dim_0'] = content_params\n",
    "trace_content_model.posterior['content_dim_0'] = content_params\n",
    "def standardize_trace(trace, var_name):\n",
    "\n",
    "    mean = trace.posterior[var_name].values.mean()\n",
    "    std = np.std(trace.posterior[var_name].values)\n",
    "    return (trace.posterior[var_name] - mean) / std\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "az.plot_forest([standardize_trace(trace_content_thurstonian, 'content'),standardize_trace(trace_content_model,'content')],\n",
    "               \n",
    "               model_names = ['simple logistic','thurstonian'], \n",
    "               combined = True, ax=ax)\n",
    "ax.axvline(0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617297cf-580d-414e-8dab-876d108c5d3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05794cab-3627-4b1a-b298-fc98f84053db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data and counts\n",
    "\n",
    "mData = prep_data_thurston(df, 'main')\n",
    "g1Data = prep_data_thurston(df, 'group1')\n",
    "g2Data = prep_data_thurston(df, 'group2')\n",
    "\n",
    "J_hum = 11\n",
    "J_non_hum = 11\n",
    "\n",
    "mJ = len(df.loc[df.group == 'main']['rater'].unique())\n",
    "g1J = len(df.loc[df.group == 'group1']['rater'].unique())\n",
    "g2J = len(df.loc[df.group == 'group2']['rater'].unique())\n",
    "\n",
    "mB = len(df.loc[df.group == 'main']['block'].unique())\n",
    "g1B = len(df.loc[df.group == 'group1']['block'].unique())\n",
    "g2B = len(df.loc[df.group == 'group1']['block'].unique())\n",
    "\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf434d-f6ec-4d9f-a3db-c353ffb9e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pm.Model() as content_thurstonian_all:\n",
    "\n",
    "    # data\n",
    "    mCONTENT = pm.MutableData('mCONTENT', mData['content_presence'])\n",
    "    g1CONTENT = pm.MutableData('g1CONTENT', g1Data['content_presence'])\n",
    "    g2CONTENT = pm.MutableData('g2CONTENT', g2Data['content_presence'])\n",
    "\n",
    "    content = pm.Normal('content',0,1,shape = (len(content_params)))\n",
    "    \n",
    "    mdot_prod = pt.dot(mCONTENT, content)\n",
    "    mdot_prod_reshaped = mdot_prod.reshape((mB,K))\n",
    "\n",
    "    g1dot_prod = pt.dot(g1CONTENT, content)\n",
    "    g1dot_prod_reshaped = g1dot_prod.reshape((g1B,K))\n",
    "\n",
    "    g2dot_prod = pt.dot(g2CONTENT, content)\n",
    "    g2dot_prod_reshaped = g2dot_prod.reshape((g2B,K))\n",
    "    \n",
    "    fields = pm.Normal('fields',0, 1,shape = (K))\n",
    "\n",
    "    paper_intercepts = pm.Normal('paper_intercepts',0,1, shape = (mB + g1B + g2B)*K)\n",
    "\n",
    "    # split the intercepts by group, and put them in the right shape by block\n",
    "    m_intercepts = paper_intercepts[:mB*K].reshape((mB, K))\n",
    "    g1_intercepts = paper_intercepts[mB*K:(mB*K) + (g1B*K)].reshape((g1B, K))\n",
    "    g2_intercepts = paper_intercepts[(mB*K) + (g1B*K):].reshape((g2B, K))\n",
    "\n",
    "    \n",
    "    mpaper_values = pm.Deterministic('mpaper_values', m_intercepts + fields[mData['fields_presence']]+ mdot_prod_reshaped )\n",
    "    g1paper_values = pm.Deterministic('g1paper_values', g1_intercepts + fields[g1Data['fields_presence']]+ g1dot_prod_reshaped )\n",
    "    g2paper_values = pm.Deterministic('g2paper_values', g2_intercepts + fields[g2Data['fields_presence']]+ g2dot_prod_reshaped )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    mmu = pm.Deterministic('mmu', pt.tile(mpaper_values[:,pt.newaxis,:],(1,mJ,1)))\n",
    "    g1mu = pm.Deterministic('g1mu', pt.tile(g1paper_values[:,pt.newaxis,:],(1,g1J,1)))\n",
    "    g2mu = pm.Deterministic('g2mu', pt.tile(g2paper_values[:,pt.newaxis,:],(1,g2J,1)))\n",
    "\n",
    "\n",
    "    mreordered_mu = pm.Deterministic('mreordered_mu', pt.take_along_axis(mmu, mData['rank_data_argsort'], axis = -1))\n",
    "    g1reordered_mu = pm.Deterministic('g1reordered_mu', pt.take_along_axis(g1mu, g1Data['rank_data_argsort'], axis = -1))\n",
    "    g2reordered_mu = pm.Deterministic('g2reordered_mu', pt.take_along_axis(g2mu, g2Data['rank_data_argsort'], axis = -1))\n",
    "\n",
    "    \n",
    "    sigma = pm.Uniform('sigma',0.01,2)\n",
    "    \n",
    "    mlatent = pm.Normal('mlatent',\n",
    "                       mu=mreordered_mu,\n",
    "                       sigma=sigma, \n",
    "                       transform=Ordered(), \n",
    "                       shape=(mB,mJ,K),\n",
    "                       # have to set test value to avoid issues with negative numbers\n",
    "                       testval=np.tile(np.tile(np.arange(K), (mB, 1))[:, np.newaxis, :], (1, mJ, 1))) \n",
    "\n",
    "    g1latent = pm.Normal('g1latent',\n",
    "                       mu=g1reordered_mu,\n",
    "                       sigma=sigma, \n",
    "                       transform=Ordered(), \n",
    "                       shape=(g1B,g1J,K),\n",
    "                       # have to set test value to avoid issues with negative numbers\n",
    "                       testval=np.tile(np.tile(np.arange(K), (g1B, 1))[:, np.newaxis, :], (1, g1J, 1)))\n",
    "    \n",
    "    g2latent = pm.Normal('latent',\n",
    "                       mu=g2reordered_mu,\n",
    "                       sigma=sigma, \n",
    "                       transform=Ordered(), \n",
    "                       shape=(g2B,g2J,K),\n",
    "                       # have to set test value to avoid issues with negative numbers\n",
    "                       testval=np.tile(np.tile(np.arange(K), (g2B, 1))[:, np.newaxis, :], (1, g2J, 1)))\n",
    "\n",
    "    mlatent_reshaped = pt.take_along_axis(mlatent, mData['rank_data'], axis = -1)\n",
    "    g1latent_reshaped = pt.take_along_axis(g1latent, g1Data['rank_data'], axis = -1)\n",
    "    g2latent_reshaped = pt.take_along_axis(g2latent, g2Data['rank_data'], axis = -1)\n",
    "\n",
    "\n",
    "    \n",
    "    # non-centered parametrization Strictness\n",
    "\n",
    "    \n",
    "    strictness_sd = pm.Uniform('strictness_sd', 0.01, 2)\n",
    "    \n",
    "    strictness_offset1 = pm.Normal('strictness_offset1', 0, 1,  shape=(1, mJ, 1))\n",
    "    strictness_offset2 = pm.Normal('strictness_offset2', 0, 1, shape=(1, g1J, 1))\n",
    "    strictness_offset3 = pm.Normal('strictness_offset3', 0, 1,  shape=(1, g2J, 1))\n",
    "    \n",
    "    mstrictness = pm.Deterministic('mstrictness', strictness_offset1 * strictness_sd)\n",
    "    g1strictness = pm.Deterministic('g1strictness', strictness_offset2 * strictness_sd)\n",
    "    g2strictness = pm.Deterministic('g2strictness', strictness_offset3 * strictness_sd)\n",
    "\n",
    "\n",
    "    mbinary = pm.Bernoulli('mbinary',logit_p = mlatent_reshaped + mstrictness, observed = mData['binary_data'])\n",
    "    g1binary = pm.Bernoulli('g1binary',logit_p = g1latent_reshaped + g1strictness, observed = g1Data['binary_data'])\n",
    "    g2binary = pm.Bernoulli('g2binary',logit_p = g2latent_reshaped + g2strictness, observed = g2Data['binary_data'])\n",
    "\n",
    "    pr9 = pm.sample_prior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae187d4-15bb-4b77-97dc-cafda7675152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with content_thurstonian_all:\n",
    "    trace_content_thurstonian_all = pm.sample(2000, tune = 1000, idata_kwargs={\"log_likelihood\": True},target_accept = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19377610-dd6d-40d5-92b6-9fa624ac15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_content_thurstonian_all.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_content_thurstonian_all.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93476bc7-826f-49e4-bf7a-a1070ce3d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_content_thurstonian_all = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_content_thurstonian_all.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c01162-ea24-4391-b968-7cd73e2fab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abstract'] = df['abstract'].astype('str')\n",
    "scores = {i:[] for i in ['group1','group2','main']}\n",
    "for i in ['group1','group2','main']:\n",
    "    for j in range(2):\n",
    "        dfx = df.loc[df.group == i].copy()\n",
    "        mscores = dfx.sort_values(['block','abstract']).groupby('abstract', sort=False)[['ordinal','binary']].sum().values\n",
    "        results = standardize(mscores[:,j])\n",
    "        scores[i].append(results)\n",
    "\n",
    "mpaper_means = np.ravel(trace_content_thurstonian_all.posterior['mpaper_values'].mean(dim = ['chain','draw']).values)\n",
    "g1paper_means = np.ravel(trace_content_thurstonian_all.posterior['g1paper_values'].mean(dim = ['chain','draw']).values)\n",
    "g2paper_means = np.ravel(trace_content_thurstonian_all.posterior['g2paper_values'].mean(dim = ['chain','draw']).values)\n",
    "\n",
    "val_estimates = np.concatenate([g1paper_means,g2paper_means,mpaper_means])\n",
    "binary_scores = np.concatenate([i[1] for i in scores.values()])\n",
    "ordinal_scores = np.concatenate([i[0] for i in scores.values()])\n",
    "\n",
    "fig, ax = plt.subplots(ncols = 3, figsize = (16,4))\n",
    "\n",
    "\n",
    "\n",
    "# normalize reviewer scores so binary and ordinal are on the same scale\n",
    "\n",
    "ax[2].scatter(y = binary_scores, x = val_estimates, color = 'r', alpha = 0.3)\n",
    "ax[2].scatter(y = ordinal_scores, x = val_estimates, color = 'b', alpha = 0.3)\n",
    "ax[2].legend(['binary sums','ordinal sums'])\n",
    "ax[2].set_title('Estimated value by reviewer scores')\n",
    "\n",
    "\n",
    "# get the regression lines\n",
    "\n",
    "y_ord = linear_regr(val_estimates, ordinal_scores)\n",
    "y_bin = linear_regr(val_estimates, binary_scores)\n",
    "\n",
    "sns.scatterplot(y = ordinal_scores, x = val_estimates, ax=ax[0])\n",
    "ax[0].plot(val_estimates, y_ord, color = 'r')\n",
    "ax[0].set_title('Regression ordinal scores / estimated value')\n",
    "\n",
    "sns.scatterplot(y = binary_scores, x = val_estimates, ax=ax[1])\n",
    "ax[1].plot(val_estimates, y_bin, color = 'r')\n",
    "ax[1].set_title('Regression binary scores / estimated value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38d499-2409-4cd6-a6dc-61d095f46eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the estimated values of the papers to the df\n",
    "\n",
    "abstracts = df.sort_values(by = ['group','block','abstract','rater']).drop_duplicates(subset = 'doi')[['doi','group','abstract']]\n",
    "\n",
    "mreplace_df = {abstracts.loc[abstracts.group == 'main']['doi'].values[i]: mpaper_means[i] for i in range(len(abstracts.loc[abstracts.group == 'main']))}\n",
    "g1replace_df = {abstracts.loc[abstracts.group == 'group1']['doi'].values[i]: g1paper_means[i]  for i in range(len(abstracts.loc[abstracts.group == 'group1']))}\n",
    "g2replace_df = {abstracts.loc[abstracts.group == 'group2']['doi'].values[i]: g2paper_means[i]  for i in range(len(abstracts.loc[abstracts.group == 'group2']))}\n",
    "\n",
    "combined = {**mreplace_df, **g1replace_df, **g2replace_df} \n",
    "\n",
    "df['estimated_value'] = df['doi'].replace(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c38ac0-346a-4ba3-adeb-a8c069e9ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_content_thurstonian_all.posterior['content_dim_0'] = content_params\n",
    "trace_content_model_all.posterior['content_dim_0'] = content_params\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "az.plot_forest([standardize_trace(trace_content_thurstonian_all, 'content'),standardize_trace(trace_content_model_all,'content')],\n",
    "               \n",
    "               model_names = ['thurstonian','simple logistic'], \n",
    "               combined = True, ax=ax)\n",
    "ax.axvline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a05d99d-c11c-47f2-9127-8773ae36a280",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Chauvinism: Chauvinism, rater_field and field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce79007-300f-42c1-8569-4a03faab9f2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Main study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70940ab-a3aa-40f9-bb52-a610fc360640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "\n",
    "J_hum = 11\n",
    "J_non_hum = 11\n",
    "K = 5\n",
    "\n",
    "mData = prep_data_thurston(df_main, 'main')\n",
    "B = 30\n",
    "J = 22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8670a-e620-4c70-bcb5-ba9709c5d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as chauvinism_thurstonian:\n",
    "\n",
    "    rater_field = pm.Normal('rater_field',0,1, shape = K+1)\n",
    "\n",
    "    fields = pm.Normal('fields',0, 1,shape = (K))\n",
    "\n",
    "    # should this have an intercept that is different for each paper?\n",
    "    paper_intercepts = pm.Normal('paper_intercepts',0,1,shape = (B,K)) \n",
    "\n",
    "    paper_values = pm.Deterministic('paper_values', paper_intercepts + fields[mData['fields_presence']])\n",
    "\n",
    "    ## Non-centered parameterization for chauvinism\n",
    "    chauv_mean = pm.Normal('chauv_mean', 0, 1)\n",
    "    chauv_sd = pm.Uniform('chauv_sd', 0.01, 2)\n",
    "    \n",
    "    c_offset_nonhum = pt.zeros((1, J_non_hum, 1))\n",
    "    mchauvinism_offset = pm.Normal('mchauvinism_offset', 0, 1, shape=(1, J_hum, 1))\n",
    "    chauvinism_hum = pm.Deterministic('chauvinism_hum', chauv_mean + chauv_sd * mchauvinism_offset)\n",
    "    chauvinism = pt.concatenate([chauvinism_hum, c_offset_nonhum], axis = 1)\n",
    "    \n",
    "    # add the chauvinism parameter to the linear model (and index it to make sure it works for the correct papers)\n",
    "    mu = pm.Deterministic('mu', pt.tile(paper_values[:,pt.newaxis,:],(1,J,1)) + (mData['chauv_array'] * chauvinism)+ rater_field[mData['rater_fields']])\n",
    "\n",
    "\n",
    "    reordered_mu = pm.Deterministic('reordered_mu', pt.take_along_axis(mu, mData['rank_data_argsort'], axis = -1) )\n",
    "    \n",
    "    sigma = pm.Uniform('sigma',0.01,2)\n",
    "    latent = pm.Normal('latent',\n",
    "                       mu=reordered_mu,\n",
    "                       sigma=sigma, \n",
    "                       transform=Ordered(), \n",
    "                       shape=(B,J,K),\n",
    "                       # have to set test value to avoid issues with negative numbers\n",
    "                       testval=np.tile(np.tile(np.arange(K), (B, 1))[:, np.newaxis, :], (1, J, 1))) \n",
    "\n",
    "    latent_reshaped = pt.take_along_axis(latent, mData['rank_data'], axis = -1)\n",
    "\n",
    "\n",
    "    strictness = pm.Normal('strictness',0,1,shape = (1,J,1))\n",
    "    binary = pm.Bernoulli('binary',logit_p = latent_reshaped + strictness, observed = mData['binary_data'])\n",
    "    pr6 = pm.sample_prior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3e547-ea54-43aa-969e-04e759857e73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with chauvinism_thurstonian:\n",
    "    trace_chauvinism_thurstonian = pm.sample(2000, tune = 1000, idata_kwargs={\"log_likelihood\": True},target_accept = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e0c89-e096-444a-bb8e-31a64e2cf456",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_chauvinism_thurstonian.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_chauvinism_thurstonian.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b55c22-1bb6-4e4a-a255-fa2c8b3ab94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_chauvinism_thurstonian = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_chauvinism_thurstonian.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f17fc-6c2f-4b95-bda8-3abac86f4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (7,5))\n",
    "az.plot_forest(trace_chauvinism_thurstonian, var_names = ['chauvinism_hum', 'chauv_mean','chauv_sd'], combined = True, ax=ax)\n",
    "\n",
    "ax.axvline(0, color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bfe106-b58c-4067-94f1-6a7b8ab175a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check association between estimated values and reviewer scores\n",
    "\n",
    "fig, ax = plt.subplots(ncols = 3, figsize = (16,4))\n",
    "\n",
    "## estimated values by reviewer scores\n",
    "mpaper_means = np.ravel(trace_chauvinism_thurstonian.posterior['paper_values'].mean(dim = ['chain','draw']).values)\n",
    "\n",
    "# normalize reviewer scores so binary and ordinal are on the same scale\n",
    "binary_sums = standardize(np.ravel(mData['binary_data'].sum(axis = 1)))\n",
    "ordinal_sums = standardize(np.ravel(mData['rank_data'].sum(axis = 1)))\n",
    "ax[2].scatter(y = binary_sums, x = mpaper_means, color = 'r', alpha = 0.3)\n",
    "ax[2].scatter(y = ordinal_sums, x = mpaper_means, color = 'b', alpha = 0.3)\n",
    "ax[2].legend(['binary sums','ordinal sums'])\n",
    "ax[2].set_title('Estimated value by reviewer scores')\n",
    "\n",
    "mscores = df_main.sort_values(['block','abstract']).groupby('abstract')[['ordinal','binary']].sum().values\n",
    "\n",
    "\n",
    "\n",
    "## regressions\n",
    "\n",
    "y_ord = linear_regr(mpaper_means, mscores[:,0])\n",
    "y_bin = linear_regr(mpaper_means, mscores[:,1])\n",
    "\n",
    "sns.scatterplot(y = mscores[:,0], x = mpaper_means, ax=ax[0])\n",
    "ax[0].plot(mpaper_means, y_ord, color = 'r')\n",
    "ax[0].set_title('Regression estimated scores and ordinal scores')\n",
    "\n",
    "sns.scatterplot(y = mscores[:,1], x = mpaper_means, ax=ax[1])\n",
    "ax[1].plot(mpaper_means, y_bin, color = 'r')\n",
    "ax[1].set_title('Regression estimated scores and ordinal scores')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866e9ec-c2f0-42f6-9864-26fcff2bb666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check difference thurstonian model and logistic regression\n",
    "# have to first create a new variable 'chauvinism_hum' that only contains the chauvinism parameter of the humanities raters in the main study\n",
    "\n",
    "# remove dimensions that are 1, to fit with the trace from the logistic regression\n",
    "trace_chauvinism_thurstonian.posterior['chauvinism_hum'] = trace_chauvinism_thurstonian.posterior['chauvinism_hum'].squeeze()\n",
    "\n",
    "# create a new variable to add to the trace of the logistic regression\n",
    "new_coords = {\n",
    "    'chain': np.arange(4),\n",
    "    'draw': np.arange(3000),\n",
    "    'new_dim': np.arange(11)\n",
    "}\n",
    "new_dims = ['chain', 'draw', 'new_dim']\n",
    "\n",
    "# select the humanities raters from the main study\n",
    "desired_raters = (df.loc[(df.group == 'main') & (df.humanities == 1)][\"rater\"].unique())\n",
    "mask = trace_chauvinism_model_all.posterior['raters_c'].coords['raters_c'].isin(desired_raters)\n",
    "matching_indices = np.where(mask)[0]\n",
    "half = trace_chauvinism_model_all.posterior['chauvinism'].isel(raters_c=matching_indices)\n",
    "\n",
    "new_variable = xr.DataArray(\n",
    "    half,\n",
    "    dims = new_dims,\n",
    "   coords = new_coords,\n",
    "    name='chauvinism_hum'\n",
    ")\n",
    "\n",
    "\n",
    "trace_chauvinism_model_all.posterior['chauvinism_hum'] = new_variable\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "az.plot_forest([trace_chauvinism_thurstonian,trace_chauvinism_model_all],\n",
    "               var_names = ['chauvinism_hum'],\n",
    "               model_names = ['thurstonian','simple logistic'], \n",
    "               combined = True, ax=ax)\n",
    "ax.axvline(0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149bf14c-31cc-47ad-b47b-f732c7d8d9e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba83d3ad-c652-4712-aae5-44cd722a5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "mData = prep_data_thurston(df, 'main')\n",
    "g1Data = prep_data_thurston(df, 'group1')\n",
    "g2Data = prep_data_thurston(df, 'group2')\n",
    "\n",
    "J_hum = 11\n",
    "J_non_hum = 11\n",
    "\n",
    "mJ = len(df.loc[df.group == 'main']['rater'].unique())\n",
    "g1J = len(df.loc[df.group == 'group1']['rater'].unique())\n",
    "g2J = len(df.loc[df.group == 'group2']['rater'].unique())\n",
    "\n",
    "mB = len(df.loc[df.group == 'main']['block'].unique())\n",
    "g1B = len(df.loc[df.group == 'group1']['block'].unique())\n",
    "g2B = len(df.loc[df.group == 'group1']['block'].unique())\n",
    "\n",
    "K = 5\n",
    "\n",
    "with pm.Model() as chauvinism_thurstonian_all:\n",
    "\n",
    "    # data\n",
    "\n",
    "    rater_field = pm.Normal('rater_field',0,1, shape = K+1)\n",
    "\n",
    "    fields_mean = pm.Normal('fields_mean', 0, 1)\n",
    "    fields_sd = pm.Uniform('fields_sd', 0.01, 2)\n",
    "    \n",
    "    fields = pm.Normal('fields',0, fields_sd,shape = (K))\n",
    "\n",
    "    # include the below if you want a hyperprior for the intercept sd\n",
    "    # paper_var = pm.Uniform('paper_var',0.01,2)\n",
    "\n",
    "    paper_intercepts = pm.Normal('paper_intercepts',0,1, shape = (mB + g1B + g2B)*K) # replace 1 by paper_var if you want to include the hyperprior for the sd\n",
    "\n",
    "    # split the intercepts by group, and put them in the right shape by block\n",
    "    m_intercepts = paper_intercepts[:mB*K].reshape((mB, K))\n",
    "    g1_intercepts = paper_intercepts[mB*K:(mB*K) + (g1B*K)].reshape((g1B, K))\n",
    "    g2_intercepts = paper_intercepts[(mB*K) + (g1B*K):].reshape((g2B, K))\n",
    "\n",
    "    ## Non-centered parameterization for chauvinism\n",
    "    chauv_mean = pm.Normal('chauv_mean', 0, 1)\n",
    "    chauv_sd = pm.Uniform('chauv_sd', 0.01, 2)\n",
    "\n",
    "    # need just zeros for the non-hum, as they cannot be chauvinistic\n",
    "    c_offset_nonhum = pt.zeros((1, J_non_hum, 1))\n",
    "    mchauvinism_offset = pm.Normal('mchauvinism_offset', 0, 1, shape=(1, J_hum, 1))\n",
    "    chauvinism_hum = pm.Deterministic('chauvinism_hum', chauv_mean + chauv_sd * mchauvinism_offset)\n",
    "    mchauvinism = pt.concatenate([chauvinism_hum, c_offset_nonhum], axis = 1)\n",
    "\n",
    "    g1chauvinism_offset = pm.Normal('g1chauvinism_offset', 0, 1, shape=(1, g1J, 1))\n",
    "    g1chauvinism = pm.Deterministic('g1chauvinism', chauv_mean + chauv_sd * g1chauvinism_offset)\n",
    "\n",
    "    g2chauvinism_offset = pm.Normal('g2chauvinism_offset', 0, 1, shape=(1, g2J, 1))\n",
    "    g2chauvinism = pm.Deterministic('g2chauvinism', chauv_mean + chauv_sd * g2chauvinism_offset)\n",
    "\n",
    "    \n",
    "    \n",
    "    mpaper_values = pm.Deterministic('mpaper_values', m_intercepts + fields[mData['fields_presence']])\n",
    "    g1paper_values = pm.Deterministic('g1paper_values', g1_intercepts + fields[g1Data['fields_presence']])\n",
    "    g2paper_values = pm.Deterministic('g2paper_values', g2_intercepts + fields[g2Data['fields_presence']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    mmu = pm.Deterministic('mmu', pt.tile(mpaper_values[:,pt.newaxis,:],(1,mJ,1))+ rater_field[mData['rater_fields']] + (mData['chauv_array'] * mchauvinism))\n",
    "    g1mu = pm.Deterministic('g1mu', pt.tile(g1paper_values[:,pt.newaxis,:],(1,g1J,1))+rater_field[g1Data['rater_fields']] + (g1Data['chauv_array'] * g1chauvinism))\n",
    "    g2mu = pm.Deterministic('g2mu', pt.tile(g2paper_values[:,pt.newaxis,:],(1,g2J,1))+ rater_field[g2Data['rater_fields']] + (g2Data['chauv_array'] * g2chauvinism))\n",
    "\n",
    "\n",
    "    mreordered_mu = pm.Deterministic('mreordered_mu', pt.take_along_axis(mmu, mData['rank_data_argsort'], axis = -1))\n",
    "    g1reordered_mu = pm.Deterministic('g1reordered_mu', pt.take_along_axis(g1mu, g1Data['rank_data_argsort'], axis = -1))\n",
    "    g2reordered_mu = pm.Deterministic('g2reordered_mu', pt.take_along_axis(g2mu, g2Data['rank_data_argsort'], axis = -1))\n",
    "\n",
    "    \n",
    "    sigma = pm.Uniform('sigma',0.01,2)\n",
    "    \n",
    "    mlatent = pm.Normal('mlatent',\n",
    "                       mu=mreordered_mu,\n",
    "                       sigma=sigma, \n",
    "                       transform=Ordered(), \n",
    "                       shape=(mB,mJ,K),\n",
    "                       # have to set test value to avoid issues with negative numbers\n",
    "                       testval=np.tile(np.tile(np.arange(K), (mB, 1))[:, np.newaxis, :], (1, mJ, 1))) \n",
    "\n",
    "    g1latent = pm.Normal('g1latent',\n",
    "                       mu=g1reordered_mu,\n",
    "                       sigma=sigma, \n",
    "                       transform=Ordered(), \n",
    "                       shape=(g1B,g1J,K),\n",
    "                       # have to set test value to avoid issues with negative numbers\n",
    "                       testval=np.tile(np.tile(np.arange(K), (g1B, 1))[:, np.newaxis, :], (1, g1J, 1)))\n",
    "    \n",
    "    g2latent = pm.Normal('g2latent',\n",
    "                       mu=g2reordered_mu,\n",
    "                       sigma=sigma, \n",
    "                       transform=Ordered(), \n",
    "                       shape=(g2B,g2J,K),\n",
    "                       # have to set test value to avoid issues with negative numbers\n",
    "                       testval=np.tile(np.tile(np.arange(K), (g2B, 1))[:, np.newaxis, :], (1, g2J, 1)))\n",
    "\n",
    "    mlatent_reshaped = pt.take_along_axis(mlatent, mData['rank_data'], axis = -1)\n",
    "    g1latent_reshaped = pt.take_along_axis(g1latent, g1Data['rank_data'], axis = -1)\n",
    "    g2latent_reshaped = pt.take_along_axis(g2latent, g2Data['rank_data'], axis = -1)\n",
    "\n",
    "\n",
    "    \n",
    "    # Strictness\n",
    "    strictness_sd = pm.Uniform('strictness_sd', 0.01, 2)\n",
    "    \n",
    "    strictness_offset1 = pm.Normal('strictness_offset1', 0, 1,  shape=(1, mJ, 1))\n",
    "    strictness_offset2 = pm.Normal('strictness_offset2', 0, 1, shape=(1, g1J, 1))\n",
    "    strictness_offset3 = pm.Normal('strictness_offset3', 0, 1,  shape=(1, g2J, 1))\n",
    "    \n",
    "    mstrictness = pm.Deterministic('mstrictness', strictness_offset1 * strictness_sd)\n",
    "    g1strictness = pm.Deterministic('g1strictness', strictness_offset2 * strictness_sd)\n",
    "    g2strictness = pm.Deterministic('g2strictness', strictness_offset3 * strictness_sd)\n",
    "\n",
    "\n",
    "    mbinary = pm.Bernoulli('mbinary',logit_p = mlatent_reshaped + mstrictness, observed = mData['binary_data'])\n",
    "    g1binary = pm.Bernoulli('g1binary',logit_p = g1latent_reshaped + g1strictness, observed = g1Data['binary_data'])\n",
    "    g2binary = pm.Bernoulli('g2binary',logit_p = g2latent_reshaped + g2strictness, observed = g2Data['binary_data'])\n",
    "\n",
    "    pr9 = pm.sample_prior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0825f7ec-39a9-41a6-b145-5c555203b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with chauvinism_thurstonian_all:\n",
    "    trace_chauvinism_thurstonian_all_varpaper = pm.sample(2000, tune = 1000, idata_kwargs={\"log_likelihood\": True},target_accept = 0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8995fdf-0418-4e78-b315-ae9400418bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace_chauvinism_thurstonian_all.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_chauvinism_thurstonian_all_varpaper.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7bb6ca3-e694-4d76-87e4-98c78aed53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_chauvinism_thurstonian_all = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_chauvinism_thurstonian_all.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aab46b9-a691-4a76-bd90-ce8d9dd3e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the trace with a hyperprior for the intercept sd\n",
    "trace_chauvinism_thurstonian_all_varpaper = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_chauvinism_thurstonian_all_varpaper.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421a8bbf-98b6-4a8c-9f64-2b0ec0240296",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (7,10))\n",
    "az.plot_forest(trace_chauvinism_thurstonian_all , var_names = ['chauv_mean','chauv_sd','chauvinism_hum','g1chauvinism','g2chauvinism'], combined = True, ax=ax)\n",
    "\n",
    "ax.axvline(0, color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f16a38c-a509-4c6e-bf6f-4cfaf6d1929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['abstract'] = df['abstract'].astype('str')\n",
    "scores = {i:[] for i in ['group1','group2','main']}\n",
    "for i in ['group1','group2','main']:\n",
    "    for j in range(2):\n",
    "        dfx = df.loc[df.group == i].copy()\n",
    "        mscores = dfx.sort_values(['block','abstract']).groupby('abstract', sort=False)[['ordinal','binary']].sum().values\n",
    "        results = standardize(mscores[:,j])\n",
    "        scores[i].append(results)\n",
    "\n",
    "mpaper_means = np.ravel(trace_chauvinism_thurstonian_all.posterior['mpaper_values'].mean(dim = ['chain','draw']).values)\n",
    "g1paper_means = np.ravel(trace_chauvinism_thurstonian_all.posterior['g1paper_values'].mean(dim = ['chain','draw']).values)\n",
    "g2paper_means = np.ravel(trace_chauvinism_thurstonian_all.posterior['g2paper_values'].mean(dim = ['chain','draw']).values)\n",
    "\n",
    "val_estimates = np.concatenate([g1paper_means,g2paper_means,mpaper_means])\n",
    "binary_scores = np.concatenate([i[1] for i in scores.values()])\n",
    "ordinal_scores = np.concatenate([i[0] for i in scores.values()])\n",
    "\n",
    "fig, ax = plt.subplots(ncols = 3, figsize = (16,4))\n",
    "\n",
    "\n",
    "\n",
    "# normalize reviewer scores so binary and ordinal are on the same scale\n",
    "\n",
    "ax[2].scatter(y = binary_scores, x = val_estimates, color = 'r', alpha = 0.3)\n",
    "ax[2].scatter(y = ordinal_scores, x = val_estimates, color = 'b', alpha = 0.3)\n",
    "ax[2].legend(['binary sums','ordinal sums'])\n",
    "ax[2].set_title('Estimated value by reviewer scores')\n",
    "\n",
    "\n",
    "# get the regression lines\n",
    "\n",
    "y_ord = linear_regr(val_estimates, ordinal_scores)\n",
    "y_bin = linear_regr(val_estimates, binary_scores)\n",
    "\n",
    "sns.scatterplot(y = ordinal_scores, x = val_estimates, ax=ax[0])\n",
    "ax[0].plot(val_estimates, y_ord, color = 'r')\n",
    "ax[0].set_title('Regression ordinal scores / estimated value')\n",
    "\n",
    "sns.scatterplot(y = binary_scores, x = val_estimates, ax=ax[1])\n",
    "ax[1].plot(val_estimates, y_bin, color = 'r')\n",
    "ax[1].set_title('Regression binary scores / estimated value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b1f8de-8f95-4ce6-afc3-fc441a2d8c6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Comparison model with and without hyperprior for sd paper_intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1447f310-9cc5-4e05-a27d-584c2ce09501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>elpd_loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>elpd_diff</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>with hyper</th>\n",
       "      <td>0</td>\n",
       "      <td>-990.681907</td>\n",
       "      <td>272.760415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>18.996754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no hyper</th>\n",
       "      <td>1</td>\n",
       "      <td>-999.770729</td>\n",
       "      <td>270.054683</td>\n",
       "      <td>9.088822</td>\n",
       "      <td>2.309264e-14</td>\n",
       "      <td>18.727002</td>\n",
       "      <td>1.276707</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rank    elpd_loo       p_loo  elpd_diff        weight         se  \\\n",
       "with hyper     0 -990.681907  272.760415   0.000000  1.000000e+00  18.996754   \n",
       "no hyper       1 -999.770729  270.054683   9.088822  2.309264e-14  18.727002   \n",
       "\n",
       "                 dse  warning scale  \n",
       "with hyper  0.000000    False   log  \n",
       "no hyper    1.276707    False   log  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {'no hyper':trace_chauvinism_thurstonian_all, 'with hyper':trace_chauvinism_thurstonian_all_varpaper}\n",
    "\n",
    "# have to check for all three likelihoods separately, but they are very similar.\n",
    "a = az.compare(models,var_name = 'mbinary')\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2956880-ea09-4b29-9455-66d3ef83939c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# expected distribution of paper_intercepts\n",
    "# note, this is variation between papers not counting the role of the content codes or the field\n",
    "\n",
    "\n",
    "sds = np.random.choice(np.ravel(trace_chauvinism_thurstonian_all_varpaper.posterior['paper_var'].values), 10000, replace = True)\n",
    "ppc_paper_intercepts = np.random.normal(0,sds)\n",
    "plt.hist(ppc_paper_intercepts, bins = 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec521ac4-cb94-4a43-85d1-457416e19b6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Field: Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3611b48c-6d5e-451e-ad66-b47c2ca0eb0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Main study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae0c41-5eda-434f-b55c-562c685d1295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "\n",
    "K = 5\n",
    "mData = prep_data_thurston(df_main, 'main')\n",
    "B = 30\n",
    "J = 22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b777007-1ad1-42c5-96f7-f14b77af7bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as field_thurstonian:\n",
    "\n",
    "\n",
    "    fields = pm.Normal('fields',0, 1,shape = (K))\n",
    "\n",
    "    # should this have an intercept that is different for each paper?\n",
    "    paper_intercepts = pm.Normal('paper_intercepts',0,1,shape = (B,K)) # \n",
    "\n",
    "    paper_values = pm.Deterministic('paper_values', paper_intercepts + fields[mData['fields_presence']] )\n",
    "\n",
    "    # add the chauvinism parameter to the linear model (and index it to make sure it works for the correct papers)\n",
    "    mu = pm.Deterministic('mu', pt.tile(paper_values[:,pt.newaxis,:],(1,J,1)))\n",
    "\n",
    "    reordered_mu = pm.Deterministic('reordered_mu', pt.take_along_axis(mu, mData['rank_data_argsort'], axis = -1))\n",
    "    sigma = pm.Uniform('sigma',0.01,2)\n",
    "    latent = pm.Normal('latent',\n",
    "                       mu=reordered_mu,\n",
    "                       sigma=sigma, \n",
    "                       transform=Ordered(), \n",
    "                       shape=(B,J,K),\n",
    "                       # have to set test value to avoid issues with negative numbers\n",
    "                       testval=np.tile(np.tile(np.arange(K), (B, 1))[:, np.newaxis, :], (1, J, 1))) \n",
    "\n",
    "    latent_reshaped = pt.take_along_axis(latent, mData['rank_data'], axis = -1)\n",
    "\n",
    "\n",
    "    strictness = pm.Normal('strictness',0,1,shape = (1,J,1))\n",
    "    binary = pm.Bernoulli('binary',logit_p = latent_reshaped + strictness, observed = mData['binary_data'])\n",
    "    pr6 = pm.sample_prior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485b035-1255-4606-9854-005b21e60bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with field_thurstonian:\n",
    "    trace_field_thurstonian = pm.sample(2000, tune = 1000, idata_kwargs={\"log_likelihood\": True},target_accept = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834b1b5-6c84-4d9e-b7b9-932020046851",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_field_thurstonian.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_field_thurstonian.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbbf91d-8db5-43f5-9240-bd75d39ce451",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_field_thurstonian = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_field_thurstonian.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d07cd-d5d0-4cf4-a85e-e377496ba494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check association between estimated values and reviewer scores\n",
    "\n",
    "fig, ax = plt.subplots(ncols = 3, figsize = (16,4))\n",
    "\n",
    "## estimated values by reviewer scores\n",
    "mpaper_means = np.ravel(trace_field_thurstonian.posterior['paper_values'].mean(dim = ['chain','draw']).values)\n",
    "\n",
    "# normalize reviewer scores so binary and ordinal are on the same scale\n",
    "binary_sums = standardize(np.ravel(mData['binary_data'].sum(axis = 1)))\n",
    "ordinal_sums = standardize(np.ravel(mData['rank_data'].sum(axis = 1)))\n",
    "ax[2].scatter(y = binary_sums, x = mpaper_means, color = 'r', alpha = 0.3)\n",
    "ax[2].scatter(y = ordinal_sums, x = mpaper_means, color = 'b', alpha = 0.3)\n",
    "ax[2].legend(['binary sums','ordinal sums'])\n",
    "ax[2].set_title('Estimated value by reviewer scores')\n",
    "\n",
    "mscores = df.loc[df.group == 'main'].sort_values(['block','abstract']).groupby('abstract')[['ordinal','binary']].sum().values\n",
    "\n",
    "\n",
    "\n",
    "## regressions\n",
    "\n",
    "y_ord = linear_regr(mpaper_means, mscores[:,0])\n",
    "y_bin = linear_regr(mpaper_means, mscores[:,1])\n",
    "\n",
    "sns.scatterplot(y = mscores[:,0], x = mpaper_means, ax=ax[0])\n",
    "ax[0].plot(mpaper_means, y_ord, color = 'r')\n",
    "ax[0].set_title('Regression estimated scores and ordinal scores')\n",
    "\n",
    "sns.scatterplot(y = mscores[:,1], x = mpaper_means, ax=ax[1])\n",
    "ax[1].plot(mpaper_means, y_bin, color = 'r')\n",
    "ax[1].set_title('Regression estimated scores and ordinal scores')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea4d53-fba5-4ee8-92dc-ac7dfbccea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check difference thurstonian model and logistic regression\n",
    "trace_field_thurstonian.posterior['fields_dim_0'] =['History','Philosophy','Religion','Linguistics','Literature']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "az.plot_forest([standardize_trace(trace_field_thurstonian, 'fields'),standardize_trace(trace_field_model,'fields')],\n",
    "               \n",
    "               model_names = ['thurstonian','simple logistic'], \n",
    "               combined = True, ax=ax)\n",
    "ax.axvline(0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a164dcc6-d429-491a-bc93-669617634f8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08396b63-de80-44c9-ac57-be007dae9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't include presence in this one\n",
    "\n",
    "mData = prep_data_thurston(df, 'main')\n",
    "g1Data = prep_data_thurston(df, 'group1')\n",
    "g2Data = prep_data_thurston(df, 'group2')\n",
    "\n",
    "\n",
    "\n",
    "mJ = len(df.loc[df.group == 'main']['rater'].unique())\n",
    "g1J = len(df.loc[df.group == 'group1']['rater'].unique())\n",
    "g2J = len(df.loc[df.group == 'group2']['rater'].unique())\n",
    "\n",
    "mB = len(df.loc[df.group == 'main']['block'].unique())\n",
    "g1B = len(df.loc[df.group == 'group1']['block'].unique())\n",
    "g2B = len(df.loc[df.group == 'group1']['block'].unique())\n",
    "\n",
    "K = 5\n",
    "\n",
    "with pm.Model() as field_thurstonian_all:\n",
    "\n",
    "    # data\n",
    "\n",
    "    fields = pm.Normal('fields',0, 1,shape = (K))\n",
    "\n",
    "    paper_intercepts = pm.Normal('paper_intercepts',0,1, shape = (mB + g1B + g2B)*K)\n",
    "\n",
    "    # split the intercepts by group, and put them in the right shape by block\n",
    "    m_intercepts = paper_intercepts[:mB*K].reshape((mB, K))\n",
    "    g1_intercepts = paper_intercepts[mB*K:(mB*K) + (g1B*K)].reshape((g1B, K))\n",
    "    g2_intercepts = paper_intercepts[(mB*K) + (g1B*K):].reshape((g2B, K))\n",
    "    \n",
    "    mpaper_values = pm.Deterministic('mpaper_values', m_intercepts + fields[mData['fields_presence']])\n",
    "    g1paper_values = pm.Deterministic('g1paper_values', g1_intercepts + fields[g1Data['fields_presence']])\n",
    "    g2paper_values = pm.Deterministic('g2paper_values', g2_intercepts + fields[g2Data['fields_presence']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    mmu = pm.Deterministic('mmu', pt.tile(mpaper_values[:,pt.newaxis,:],(1,mJ,1)))\n",
    "    g1mu = pm.Deterministic('g1mu', pt.tile(g1paper_values[:,pt.newaxis,:],(1,g1J,1)))\n",
    "    g2mu = pm.Deterministic('g2mu', pt.tile(g2paper_values[:,pt.newaxis,:],(1,g2J,1)))\n",
    "\n",
    "\n",
    "    mreordered_mu = pm.Deterministic('mreordered_mu', pt.take_along_axis(mmu, mData['rank_data_argsort'], axis = -1))\n",
    "    g1reordered_mu = pm.Deterministic('g1reordered_mu', pt.take_along_axis(g1mu, g1Data['rank_data_argsort'], axis = -1))\n",
    "    g2reordered_mu = pm.Deterministic('g2reordered_mu', pt.take_along_axis(g2mu, g2Data['rank_data_argsort'], axis = -1))\n",
    "\n",
    "    \n",
    "    sigma = pm.Uniform('sigma',0.01,2)\n",
    "    \n",
    "    mlatent = pm.Normal('mlatent',\n",
    "                       mu=mreordered_mu,\n",
    "                       sigma=sigma, \n",
    "                       transform=Ordered(), \n",
    "                       shape=(mB,mJ,K),\n",
    "                       # have to set test value to avoid issues with negative numbers\n",
    "                       testval=np.tile(np.tile(np.arange(K), (mB, 1))[:, np.newaxis, :], (1, mJ, 1))) \n",
    "\n",
    "    g1latent = pm.Normal('g1latent',\n",
    "                       mu=g1reordered_mu,\n",
    "                       sigma=sigma, \n",
    "                       transform=Ordered(), \n",
    "                       shape=(g1B,g1J,K),\n",
    "                       # have to set test value to avoid issues with negative numbers\n",
    "                       testval=np.tile(np.tile(np.arange(K), (g1B, 1))[:, np.newaxis, :], (1, g1J, 1)))\n",
    "    \n",
    "    g2latent = pm.Normal('latent',\n",
    "                       mu=g2reordered_mu,\n",
    "                       sigma=sigma, \n",
    "                       transform=Ordered(), \n",
    "                       shape=(g2B,g2J,K),\n",
    "                       # have to set test value to avoid issues with negative numbers\n",
    "                       testval=np.tile(np.tile(np.arange(K), (g2B, 1))[:, np.newaxis, :], (1, g2J, 1)))\n",
    "\n",
    "    mlatent_reshaped = pt.take_along_axis(mlatent, mData['rank_data'], axis = -1)\n",
    "    g1latent_reshaped = pt.take_along_axis(g1latent, g1Data['rank_data'], axis = -1)\n",
    "    g2latent_reshaped = pt.take_along_axis(g2latent, g2Data['rank_data'], axis = -1)\n",
    "\n",
    "\n",
    "    \n",
    "    # Strictness\n",
    "    \n",
    "    strictness_sd = pm.Uniform('strictness_sd', 0.01, 2)\n",
    "    \n",
    "    strictness_offset1 = pm.Normal('strictness_offset1', 0, 1,  shape=(1, mJ, 1))\n",
    "    strictness_offset2 = pm.Normal('strictness_offset2', 0, 1, shape=(1, g1J, 1))\n",
    "    strictness_offset3 = pm.Normal('strictness_offset3', 0, 1,  shape=(1, g2J, 1))\n",
    "    \n",
    "    mstrictness = pm.Deterministic('mstrictness', strictness_offset1 * strictness_sd)\n",
    "    g1strictness = pm.Deterministic('g1strictness', strictness_offset2 * strictness_sd)\n",
    "    g2strictness = pm.Deterministic('g2strictness', strictness_offset3 * strictness_sd)\n",
    "\n",
    "\n",
    "    mbinary = pm.Bernoulli('mbinary',logit_p = mlatent_reshaped + mstrictness, observed = mData['binary_data'])\n",
    "    g1binary = pm.Bernoulli('g1binary',logit_p = g1latent_reshaped + g1strictness, observed = g1Data['binary_data'])\n",
    "    g2binary = pm.Bernoulli('g2binary',logit_p = g2latent_reshaped + g2strictness, observed = g2Data['binary_data'])\n",
    "\n",
    "    pr9 = pm.sample_prior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bd114-f88e-4ba2-bca9-c938902e6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with field_thurstonian_all:\n",
    "    trace_field_thurstonian_all = pm.sample(2000, tune = 1000, idata_kwargs={\"log_likelihood\": True},target_accept = 0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9723a4-95e2-47d5-b73f-c84f9a7a1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_field_thurstonian_all.to_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_field_thurstonian_all.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a9f2a-2c14-4ded-915c-e19df9d010b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_field_thurstonian_all = az.from_netcdf(r\"C:\\Users\\conix\\Documents\\IIH_localtraces\\trace_field_thurstonian_all.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee63a57-8216-4f5e-bac0-fc1a679b084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with field_thurstonian_all:\n",
    "    ppc = pm.sample_posterior_predictive(trace_field_thurstonian_all, var_names = ['mpaper_values','g1paper_values', 'mbinary','g1binary','g2binary','g2paper_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a498b1-41e5-4891-8e05-bb1335b0d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['abstract'] = df['abstract'].astype('str')\n",
    "scores = {i:[] for i in ['group1','group2','main']}\n",
    "for i in ['group1','group2','main']:\n",
    "    for j in range(2):\n",
    "        dfx = df.loc[df.group == i].copy()\n",
    "        mscores = dfx.sort_values(['block','abstract']).groupby('abstract', sort=False)[['ordinal','binary']].sum().values\n",
    "        results = standardize(mscores[:,j])\n",
    "        scores[i].append(results)\n",
    "\n",
    "mpaper_means = np.ravel(trace_field_thurstonian_all.posterior['mpaper_values'].mean(dim = ['chain','draw']).values)\n",
    "g1paper_means = np.ravel(trace_field_thurstonian_all.posterior['g1paper_values'].mean(dim = ['chain','draw']).values)\n",
    "g2paper_means = np.ravel(trace_field_thurstonian_all.posterior['g2paper_values'].mean(dim = ['chain','draw']).values)\n",
    "\n",
    "val_estimates = np.concatenate([g1paper_means,g2paper_means,mpaper_means])\n",
    "binary_scores = np.concatenate([i[1] for i in scores.values()])\n",
    "ordinal_scores = np.concatenate([i[0] for i in scores.values()])\n",
    "\n",
    "fig, ax = plt.subplots(ncols = 3, figsize = (16,4))\n",
    "\n",
    "\n",
    "\n",
    "# normalize reviewer scores so binary and ordinal are on the same scale\n",
    "\n",
    "ax[2].scatter(y = binary_scores, x = val_estimates, color = 'r', alpha = 0.3)\n",
    "ax[2].scatter(y = ordinal_scores, x = val_estimates, color = 'b', alpha = 0.3)\n",
    "ax[2].legend(['binary sums','ordinal sums'])\n",
    "ax[2].set_title('Estimated value by reviewer scores')\n",
    "\n",
    "\n",
    "# get the regression lines\n",
    "\n",
    "y_ord = linear_regr(val_estimates, ordinal_scores)\n",
    "y_bin = linear_regr(val_estimates, binary_scores)\n",
    "\n",
    "sns.scatterplot(y = ordinal_scores, x = val_estimates, ax=ax[0])\n",
    "ax[0].plot(val_estimates, y_ord, color = 'r')\n",
    "ax[0].set_title('Regression ordinal scores / estimated value')\n",
    "\n",
    "sns.scatterplot(y = binary_scores, x = val_estimates, ax=ax[1])\n",
    "ax[1].plot(val_estimates, y_bin, color = 'r')\n",
    "ax[1].set_title('Regression binary scores / estimated value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f843d9-a8fb-40f6-b114-d8cfb355b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_field_thurstonian_all.posterior['fields_dim_0'] =['History','Philosophy','Religion','Linguistics','Literature']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "az.plot_forest(trace_field_thurstonian_all, var_names = 'fields',combined = True, ax=ax)\n",
    "ax.axvline(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
