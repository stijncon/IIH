{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7fba87d7-358a-4bc1-9cfe-4738537a9359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from QualtricsAPI.Setup import Credentials\n",
    "from QualtricsAPI.Survey import Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1381bb79-0037-42fa-8bb6-0c255c4f02dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# credentials to get data via the qualtrics API\n",
    "\n",
    "id_s1 = 'SV_0O0EKLOMn3AEoLQ'\n",
    "id_s2 = 'SV_8pGlqv9GqN2OrVI'\n",
    "id_s3 = 'SV_bQ75Bb7jwCEnHBI'\n",
    "\n",
    "qtoken ='...' # safer to remove\n",
    "            \n",
    "qdc = 'fra1'\n",
    "\n",
    "# import data through API\n",
    "\n",
    "Credentials().qualtrics_api_credentials(token=qtoken,data_center=qdc)\n",
    "\n",
    "df = Responses().get_survey_responses(survey=id_s1)\n",
    "df2 = Responses().get_survey_responses(survey=id_s2)\n",
    "df3 = Responses().get_survey_responses(survey=id_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "af5916b3-5853-4e7a-b347-631c864de2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# quick cleanup of the data\n",
    "\n",
    "dropcols = ([ 'RecordedDate','ResponseId','RecipientLastName','RecipientFirstName','RecipientEmail','ExternalReference',\n",
    "             'LocationLatitude','LocationLongitude','DistributionChannel','UserLanguage', 'Status','IPAddress', 'Finished'])\n",
    "\n",
    "df = df.drop(columns = dropcols)\n",
    "\n",
    "# only finished surveys\n",
    "\n",
    "# df = df.loc[df.Progress == '100']\n",
    "\n",
    "# store and remove duration\n",
    "\n",
    "duration = df.loc[df.Progress == '100'][['Q1','Duration (in seconds)']]\n",
    "df = df.drop(columns = ['Duration (in seconds)'])\n",
    "\n",
    "# store and remove dates\n",
    "\n",
    "dates = df.loc[df.Progress == '100'][['Q1','StartDate','EndDate']]\n",
    "df = df.drop(columns = ['StartDate','EndDate'])\n",
    "\n",
    "# remove the timer columns except for total block time\n",
    "\n",
    "timer_cols = [i for i in df.columns if (('First' in i) or ('Last' in i) or ('Count' in i))]\n",
    "\n",
    "df = df.drop(columns = timer_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7a947bed-94a2-4de0-becb-c11813172525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions to check time and consistency\n",
    "\n",
    "def get_scores(rater_code, df):\n",
    "    # get all the scores for one rater, and split them up by block\n",
    "    rater_results = [list(df.loc[df.Q1 == rater_code].iloc[0,:].values[i:i+10]) for i in range(2,len(df.columns) - 2,11)]\n",
    "    \n",
    "    # separate into rank and binary scores\n",
    "    rank_scores = np.array(rater_results)[:,::2]\n",
    "    binary_scores = np.array(rater_results)[:,1::2]\n",
    "    \n",
    "    return {\"rank_scores\":rank_scores,\"binary_scores\":binary_scores}\n",
    "\n",
    "def check_consistency(scores):\n",
    "    \n",
    "    # get the indices that would order the rank scores, and use this to order to binary scores\n",
    "    rank_argsort = np.argsort(scores[\"rank_scores\"], axis = 1)\n",
    "    binary_argsort = np.take_along_axis(scores[\"binary_scores\"],rank_argsort,1)\n",
    "    \n",
    "    # check if the binary scores ordered by rank scores never have 0s before 1s\n",
    "    \n",
    "    consistency_lst = []\n",
    "    \n",
    "    for i in binary_argsort:\n",
    "        if sorted(list(i),reverse=True) != list(i):\n",
    "            consistency_lst.append(0)\n",
    "\n",
    "        else:\n",
    "            consistency_lst.append(1)\n",
    "            \n",
    "    return np.array(consistency_lst)\n",
    "\n",
    "def check_times(rater_code, df):\n",
    "    \n",
    "    # get the total block time for all blocks\n",
    "    time = [float(df.loc[df.Q1 == rater_code].iloc[0,:].values[i]) for i in range(12,len(df.columns) ,11)]\n",
    "    \n",
    "    return np.array(time)\n",
    "\n",
    "def print_results(consistency_lst, time):\n",
    "\n",
    "    # print the blocks that were inconsistent\n",
    "    print(f\"The rater was inconsistent in blocks {np.where(consistency_lst == 0)[0]}\")\n",
    "    \n",
    "    # print the blocks that were done too rapidly\n",
    "    print(f\"The rater took too little time in blocks {np.where(time < 100)[0]}\")\n",
    "    \n",
    "\n",
    "def check_results(rater_code, df):\n",
    "    \n",
    "    scores = get_scores(rater_code, df)\n",
    "    consistency = check_consistency(scores)\n",
    "    time = check_times(rater_code, df)\n",
    "    print_results(consistency, time)\n",
    "    \n",
    "\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5452578c-0b8e-4e5a-b326-50e7016f206f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rater was inconsistent in blocks [1 2 3]\n",
      "The rater took too little time in blocks [ 1  2  3  4  5  6  7  8  9 10 11 12]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "check_results('STIJN2',df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
